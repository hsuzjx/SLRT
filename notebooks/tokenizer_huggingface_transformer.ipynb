{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T12:10:47.616041Z",
     "start_time": "2024-09-14T12:10:47.610188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ! export http_proxy=http://10.12.44.139:7890\n",
    "# ! export https_proxy=http://10.12.44.139:7890\n"
   ],
   "id": "2607ae8de32ccdef",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-14T12:10:48.341412Z",
     "start_time": "2024-09-14T12:10:47.676262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 示例数据\n",
    "texts = [\n",
    "    \"I love programming in Python\",\n",
    "    \"Python is a great language\",\n",
    "    \"Programming is fun\"\n",
    "]\n",
    "labels = [1, 1, 0]  # 假设 1 表示正面评价，0 表示负面评价\n",
    "\n",
    "# 加载预训练的分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"../.pretrained_models/bert-base-cased\",\n",
    "    clean_up_tokenization_spaces=True\n",
    ")\n",
    "\n",
    "\n",
    "# 定义数据集类\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=10):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # 使用分词器进行分词和编码\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        input_ids = encoding['input_ids'].squeeze(0)\n",
    "        attention_mask = encoding['attention_mask'].squeeze(0)\n",
    "\n",
    "        return input_ids, attention_mask, torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "\n",
    "# 创建数据集\n",
    "dataset = TextDataset(texts, labels, tokenizer)\n",
    "\n",
    "# 创建数据加载器\n",
    "batch_size = 2\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 打印数据集中的一个批次\n",
    "for batch in data_loader:\n",
    "    input_ids, attention_mask, targets = batch\n",
    "    print(\"Input IDs:\", input_ids)\n",
    "    print(\"Attention Mask:\", attention_mask)\n",
    "    print(\"Targets:\", targets)\n",
    "    break\n",
    "\n",
    "# 打印分词器的词汇表大小\n",
    "print(\"Vocabulary size:\", len(tokenizer))\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: tensor([[  101, 21076,  1110,  4106,   102,     0,     0,     0,     0,     0],\n",
      "        [  101, 23334,  1110,   170,  1632,  1846,   102,     0,     0,     0]])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])\n",
      "Targets: tensor([0., 1.])\n",
      "Vocabulary size: 28996\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T12:12:55.201643Z",
     "start_time": "2024-09-14T12:12:55.191395Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer",
   "id": "a388ca84579d134c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='../.pretrained_models/bert-base-cased', vocab_size=28996, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T12:13:12.096343Z",
     "start_time": "2024-09-14T12:13:12.083720Z"
    }
   },
   "cell_type": "code",
   "source": "dir(tokenizer)",
   "id": "92236ed991a845c7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SPECIAL_TOKENS_ATTRIBUTES',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_tokens',\n",
       " '_additional_special_tokens',\n",
       " '_auto_class',\n",
       " '_batch_encode_plus',\n",
       " '_bos_token',\n",
       " '_call_one',\n",
       " '_cls_token',\n",
       " '_compile_jinja_template',\n",
       " '_convert_encoding',\n",
       " '_convert_id_to_token',\n",
       " '_convert_token_to_id_with_added_voc',\n",
       " '_create_repo',\n",
       " '_decode',\n",
       " '_decode_use_source_tokenizer',\n",
       " '_encode_plus',\n",
       " '_eos_token',\n",
       " '_eventual_warn_about_too_long_sequence',\n",
       " '_eventually_correct_t5_max_length',\n",
       " '_from_pretrained',\n",
       " '_get_files_timestamps',\n",
       " '_get_padding_truncation_strategies',\n",
       " '_in_target_context_manager',\n",
       " '_mask_token',\n",
       " '_pad',\n",
       " '_pad_token',\n",
       " '_pad_token_type_id',\n",
       " '_processor_class',\n",
       " '_render_with_assistant_indices',\n",
       " '_save_pretrained',\n",
       " '_sep_token',\n",
       " '_set_processor_class',\n",
       " '_switch_to_input_mode',\n",
       " '_switch_to_target_mode',\n",
       " '_tokenizer',\n",
       " '_unk_token',\n",
       " '_upload_modified_files',\n",
       " 'add_special_tokens',\n",
       " 'add_tokens',\n",
       " 'added_tokens_decoder',\n",
       " 'added_tokens_encoder',\n",
       " 'additional_special_tokens',\n",
       " 'additional_special_tokens_ids',\n",
       " 'all_special_ids',\n",
       " 'all_special_tokens',\n",
       " 'all_special_tokens_extended',\n",
       " 'apply_chat_template',\n",
       " 'as_target_tokenizer',\n",
       " 'backend_tokenizer',\n",
       " 'batch_decode',\n",
       " 'batch_encode_plus',\n",
       " 'bos_token',\n",
       " 'bos_token_id',\n",
       " 'build_inputs_with_special_tokens',\n",
       " 'can_save_slow_tokenizer',\n",
       " 'chat_template',\n",
       " 'clean_up_tokenization',\n",
       " 'clean_up_tokenization_spaces',\n",
       " 'cls_token',\n",
       " 'cls_token_id',\n",
       " 'convert_added_tokens',\n",
       " 'convert_ids_to_tokens',\n",
       " 'convert_tokens_to_ids',\n",
       " 'convert_tokens_to_string',\n",
       " 'create_token_type_ids_from_sequences',\n",
       " 'decode',\n",
       " 'decoder',\n",
       " 'deprecation_warnings',\n",
       " 'do_lower_case',\n",
       " 'encode',\n",
       " 'encode_plus',\n",
       " 'eos_token',\n",
       " 'eos_token_id',\n",
       " 'from_pretrained',\n",
       " 'get_added_vocab',\n",
       " 'get_chat_template',\n",
       " 'get_special_tokens_mask',\n",
       " 'get_vocab',\n",
       " 'init_inputs',\n",
       " 'init_kwargs',\n",
       " 'is_fast',\n",
       " 'mask_token',\n",
       " 'mask_token_id',\n",
       " 'max_len_sentences_pair',\n",
       " 'max_len_single_sentence',\n",
       " 'model_input_names',\n",
       " 'model_max_length',\n",
       " 'name_or_path',\n",
       " 'num_special_tokens_to_add',\n",
       " 'pad',\n",
       " 'pad_token',\n",
       " 'pad_token_id',\n",
       " 'pad_token_type_id',\n",
       " 'padding_side',\n",
       " 'prepare_for_model',\n",
       " 'prepare_seq2seq_batch',\n",
       " 'pretrained_vocab_files_map',\n",
       " 'push_to_hub',\n",
       " 'register_for_auto_class',\n",
       " 'sanitize_special_tokens',\n",
       " 'save_pretrained',\n",
       " 'save_vocabulary',\n",
       " 'sep_token',\n",
       " 'sep_token_id',\n",
       " 'set_truncation_and_padding',\n",
       " 'slow_tokenizer_class',\n",
       " 'special_tokens_map',\n",
       " 'special_tokens_map_extended',\n",
       " 'split_special_tokens',\n",
       " 'tokenize',\n",
       " 'train_new_from_iterator',\n",
       " 'truncate_sequences',\n",
       " 'truncation_side',\n",
       " 'unk_token',\n",
       " 'unk_token_id',\n",
       " 'verbose',\n",
       " 'vocab',\n",
       " 'vocab_files_names',\n",
       " 'vocab_size']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T12:13:54.572426Z",
     "start_time": "2024-09-14T12:13:54.548021Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.vocab.__len__()",
   "id": "3c04735b540f416d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28996"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T12:14:15.655938Z",
     "start_time": "2024-09-14T12:14:15.630046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"../.pretrained_models/bert-base-chinese\",\n",
    "    clean_up_tokenization_spaces=True\n",
    ")"
   ],
   "id": "7ac82ef526f40425",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T12:14:45.633951Z",
     "start_time": "2024-09-14T12:14:45.624504Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.vocab_size",
   "id": "c4ca3781e003a7ba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21128"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T12:15:09.420164Z",
     "start_time": "2024-09-14T12:15:09.385189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"../.pretrained_models/bert-base-german-cased\",\n",
    "    clean_up_tokenization_spaces=True\n",
    ")"
   ],
   "id": "708d7ab12b2a607b",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T12:15:17.199353Z",
     "start_time": "2024-09-14T12:15:17.169195Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.vocab",
   "id": "8756b3eb9097fec6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Beschwerde': 2243,\n",
       " '##läuf': 2270,\n",
       " '##unsten': 5403,\n",
       " 'rechtswidrig': 9453,\n",
       " '##weisung': 4599,\n",
       " 'Vorstand': 6287,\n",
       " '190': 1910,\n",
       " 'Boy': 20187,\n",
       " 'Antragsteller': 3384,\n",
       " 'genügt': 8612,\n",
       " '[unused2774]': 29773,\n",
       " '##ilian': 8718,\n",
       " 'bestellte': 25313,\n",
       " '[unused421]': 27420,\n",
       " 'sach': 4965,\n",
       " 'spezialisierte': 24583,\n",
       " 'sorgen': 9103,\n",
       " '##abel': 3549,\n",
       " 'ruhig': 17867,\n",
       " 'nacheinander': 22363,\n",
       " 'Wuchs': 26745,\n",
       " '##Prof': 13162,\n",
       " 'verspä': 21065,\n",
       " '##cuador': 25992,\n",
       " 'emerit': 22617,\n",
       " 'Betätigung': 26609,\n",
       " '[unused2625]': 29624,\n",
       " '[unused643]': 27642,\n",
       " '##ikel': 3868,\n",
       " 'Bewerbung': 18543,\n",
       " 'Wolff': 19292,\n",
       " 'Doch': 1679,\n",
       " 'inform': 5867,\n",
       " 'gefährdet': 11110,\n",
       " 'hohen': 3661,\n",
       " 'Cav': 19988,\n",
       " '##lagern': 10191,\n",
       " 'werde': 1631,\n",
       " 'Fürstentum': 23390,\n",
       " '[unused2702]': 29701,\n",
       " 'Roma': 18487,\n",
       " 'Wechsel': 4772,\n",
       " 'Folgezeit': 12952,\n",
       " '##strei': 24495,\n",
       " '##oldung': 22103,\n",
       " 'grün': 2559,\n",
       " '##Bahn': 5289,\n",
       " 'erscheinen': 6339,\n",
       " 'pf': 6699,\n",
       " '##folger': 3199,\n",
       " 'Wohngebiet': 25157,\n",
       " '##100': 26547,\n",
       " 'Kant': 3686,\n",
       " 'Widerstands': 21323,\n",
       " '##ellen': 1039,\n",
       " 'Range': 23937,\n",
       " '##Berg': 17099,\n",
       " 'Richtung': 3134,\n",
       " '##etzt': 422,\n",
       " 'Trocken': 14647,\n",
       " '##ark': 637,\n",
       " '##Liga': 16160,\n",
       " 'Stirn': 18809,\n",
       " 'De': 576,\n",
       " '##psych': 14075,\n",
       " 'schw': 1789,\n",
       " 'zwischen': 597,\n",
       " '##zugehörigkeit': 19363,\n",
       " '##üt': 503,\n",
       " '##ächtige': 22031,\n",
       " 'Chr': 1193,\n",
       " 'Ehemann': 8147,\n",
       " 'Bayerischen': 8474,\n",
       " 'Amtszeit': 8850,\n",
       " '##igar': 11982,\n",
       " '[unused1490]': 28489,\n",
       " '[unused2740]': 29739,\n",
       " 'missbraucht': 26085,\n",
       " '##führungen': 4326,\n",
       " '##Man': 13041,\n",
       " '##/12,': 17202,\n",
       " '##show': 25138,\n",
       " 'Metho': 5778,\n",
       " 'Dynam': 12014,\n",
       " '68': 10437,\n",
       " '##arifvertrag': 22967,\n",
       " 'Kreu': 14956,\n",
       " '##öck': 16226,\n",
       " '##Dem': 12939,\n",
       " 'Spieler': 3158,\n",
       " 'Europa': 2472,\n",
       " 'Nachdem': 2674,\n",
       " 'sonder': 23351,\n",
       " '##BGBl': 13875,\n",
       " '##bewertung': 20565,\n",
       " '[unused1141]': 28140,\n",
       " '##ährung': 4271,\n",
       " '[unused209]': 27208,\n",
       " 'Liegen': 22339,\n",
       " 'Großherzogt': 21175,\n",
       " 'Wern': 23563,\n",
       " '##andelte': 5834,\n",
       " 'nordöstlich': 11200,\n",
       " 'cir': 16853,\n",
       " '##/09,': 17814,\n",
       " '##ungsplan': 6445,\n",
       " '##erste': 20972,\n",
       " '##klagten': 10361,\n",
       " 'sel': 1982,\n",
       " 'Sucht': 23634,\n",
       " '##ichteten': 6172,\n",
       " 'herkömm': 16738,\n",
       " 'Observ': 25141,\n",
       " '[unused936]': 27935,\n",
       " '##genz': 17615,\n",
       " 'Part': 862,\n",
       " 'Inst': 4028,\n",
       " '##hänge': 15965,\n",
       " '[unused1650]': 28649,\n",
       " 'Mess': 5512,\n",
       " 'Indonesien': 22346,\n",
       " '##Mat': 23519,\n",
       " 'privater': 18701,\n",
       " '[unused2339]': 29338,\n",
       " 'Kommunikations': 13563,\n",
       " 'diesen': 1377,\n",
       " 'hellen': 23218,\n",
       " '##zusehen': 7349,\n",
       " '##drucks': 14970,\n",
       " '##platte': 10935,\n",
       " '##bö': 13802,\n",
       " 'Fox': 17710,\n",
       " '[unused344]': 27343,\n",
       " 'Nordost': 19325,\n",
       " 'Null': 12841,\n",
       " '##soft': 14202,\n",
       " '##one': 1949,\n",
       " 'Betriebe': 11201,\n",
       " 'verbreitete': 17027,\n",
       " 'erz': 1892,\n",
       " '##ichtung': 9076,\n",
       " '[unused1323]': 28322,\n",
       " 'iPh': 20540,\n",
       " '[unused2107]': 29106,\n",
       " '##deten': 2211,\n",
       " '##kus': 16561,\n",
       " '##ocht': 17645,\n",
       " '##fest': 2384,\n",
       " '[unused1211]': 28210,\n",
       " 'berühmten': 13707,\n",
       " 'existenzbedro': 16826,\n",
       " 'völlig': 5047,\n",
       " '1954': 6940,\n",
       " 'eingestuft': 13050,\n",
       " '##blau': 17251,\n",
       " 'Kay': 19151,\n",
       " '##eint': 1327,\n",
       " 'Gesetzgeb': 20277,\n",
       " '[unused1017]': 28016,\n",
       " 'nachvollziehbar': 10282,\n",
       " 'aus': 147,\n",
       " '##losigkeit': 7301,\n",
       " '[unused677]': 27676,\n",
       " 'Angeles': 7850,\n",
       " 'Gutschker': 17239,\n",
       " '##yer': 3351,\n",
       " 'ergänzenden': 24161,\n",
       " '[unused1585]': 28584,\n",
       " '##lingen': 4094,\n",
       " '##rechter': 12771,\n",
       " 'stark': 2047,\n",
       " 'Office': 24611,\n",
       " '##verständlich': 11810,\n",
       " 'ruhen': 25993,\n",
       " 'familiären': 26834,\n",
       " '[unused980]': 27979,\n",
       " '##bourne': 18008,\n",
       " '##kler': 21188,\n",
       " '##ruhen': 17681,\n",
       " 'Drum': 25153,\n",
       " '##attungs': 23314,\n",
       " 'mon': 9403,\n",
       " '##reibe': 23681,\n",
       " 'Tha': 11316,\n",
       " '##onne': 10715,\n",
       " '[unused1117]': 28116,\n",
       " 'KG': 8129,\n",
       " 'Lokomotive': 22612,\n",
       " '##maßstab': 18021,\n",
       " 'inter': 2556,\n",
       " 'Dienstag': 4674,\n",
       " '##vern': 13624,\n",
       " '[unused2553]': 29552,\n",
       " 'Heilige': 21059,\n",
       " 'Viele': 4523,\n",
       " 'ordnete': 19741,\n",
       " 'andererseits': 7933,\n",
       " 'Brutt': 16397,\n",
       " 'begründen': 8610,\n",
       " 'Produ': 1645,\n",
       " '##egal': 25259,\n",
       " '##kirche': 3544,\n",
       " '[unused921]': 27920,\n",
       " 'September': 1259,\n",
       " 'üpp': 26564,\n",
       " 'ausgest': 20554,\n",
       " '##ekul': 8970,\n",
       " '[unused_punctuation17]': 6393,\n",
       " 'vorläufig': 9760,\n",
       " '##Zeitung': 10961,\n",
       " '##ugoslaw': 11942,\n",
       " '[unused81]': 27080,\n",
       " 'Orientierung': 19759,\n",
       " '[unused1842]': 28841,\n",
       " 'endgültig': 7579,\n",
       " 'Teilchen': 22494,\n",
       " '[unused181]': 27180,\n",
       " 'Gewässer': 11723,\n",
       " 'bewaffnete': 14064,\n",
       " 'Stücken': 23767,\n",
       " 'korrig': 14966,\n",
       " 'Elemente': 9550,\n",
       " '§7': 9514,\n",
       " '##glo': 16189,\n",
       " '##Gesch': 7262,\n",
       " 'übrigen': 4968,\n",
       " 'Christopher': 17738,\n",
       " '##Spiele': 26502,\n",
       " 'Behinder': 8787,\n",
       " '##manager': 13116,\n",
       " 'fester': 23952,\n",
       " '##serklärung': 14181,\n",
       " '##ek': 1752,\n",
       " 'Louise': 24406,\n",
       " '##üchse': 26776,\n",
       " '##ellschaft': 1204,\n",
       " 'liefen': 20314,\n",
       " 'States': 12946,\n",
       " '##ßen': 449,\n",
       " 'Schicksal': 11391,\n",
       " 'Zahlen': 5846,\n",
       " '##nr': 12198,\n",
       " '##steigen': 6686,\n",
       " 'Und': 1356,\n",
       " '1937': 7368,\n",
       " 'Music': 8912,\n",
       " '##err': 5754,\n",
       " '##iwod': 13891,\n",
       " '[unused612]': 27611,\n",
       " 'Stufen': 13483,\n",
       " 'Kla': 5993,\n",
       " 'Bann': 17398,\n",
       " 'Sachlage': 25725,\n",
       " 'zusätzlich': 4699,\n",
       " '[unused2020]': 29019,\n",
       " '##bury': 14719,\n",
       " 'Polar': 21939,\n",
       " 'Laufen': 26885,\n",
       " 'Industri': 20105,\n",
       " 'lehnt': 18121,\n",
       " 'Ausgestaltung': 14705,\n",
       " '##unschwei': 8116,\n",
       " '##m': 26911,\n",
       " 'elf': 5918,\n",
       " 'Besser': 14510,\n",
       " 'Erlangen': 17954,\n",
       " 'I': 103,\n",
       " 'ernannte': 11531,\n",
       " '##ober': 932,\n",
       " 'Schmal': 17143,\n",
       " '##station': 7051,\n",
       " '##sprech': 1258,\n",
       " 'verwirk': 13454,\n",
       " '~': 26997,\n",
       " '##/07,': 20980,\n",
       " 'Medaille': 15754,\n",
       " '##itus': 16149,\n",
       " 'weiten': 13363,\n",
       " '##verletzungen': 17914,\n",
       " '##eira': 16667,\n",
       " '##49': 7673,\n",
       " 'dar': 390,\n",
       " 'betreffen': 5591,\n",
       " 'Einbeziehung': 14869,\n",
       " '##komp': 6575,\n",
       " 'Mül': 25662,\n",
       " '##Ph': 11115,\n",
       " 'Biologie': 20892,\n",
       " 'Hunger': 22107,\n",
       " '##undert': 941,\n",
       " '##_2': 16938,\n",
       " 'notiert': 26648,\n",
       " 'trag': 12856,\n",
       " 'bewahrt': 24976,\n",
       " 'Buddh': 24897,\n",
       " '##ossen': 3309,\n",
       " 'Pier': 8362,\n",
       " '##klassigen': 16732,\n",
       " 'Anspruch': 1916,\n",
       " 'Option': 19190,\n",
       " 'knapp': 3349,\n",
       " '##bungen': 9577,\n",
       " 'Abm': 13334,\n",
       " '##ft': 136,\n",
       " 'Bei': 467,\n",
       " '##App': 16213,\n",
       " 'rest': 8570,\n",
       " 'Graf': 3852,\n",
       " 'verworfen': 17944,\n",
       " 'Aufwand': 9095,\n",
       " 'Gabriel': 10536,\n",
       " '18-': 20981,\n",
       " 'vermeiden': 9050,\n",
       " '##Mit': 4002,\n",
       " 'Verfü': 2398,\n",
       " 'Brücke': 7053,\n",
       " 'nachhaltig': 18019,\n",
       " 'Musik': 1534,\n",
       " 'arbeitet': 5044,\n",
       " '##gemä': 9000,\n",
       " 'nannte': 7411,\n",
       " 'Route': 13172,\n",
       " ',': 26918,\n",
       " '[unused856]': 27855,\n",
       " 'Partnern': 25589,\n",
       " '##phan': 8997,\n",
       " 'Dietrich': 14059,\n",
       " '[unused881]': 27880,\n",
       " 'herausra': 14514,\n",
       " 'Üb': 3395,\n",
       " 'weisen': 9410,\n",
       " '##werkstatt': 21280,\n",
       " '##ungsverfügung': 15662,\n",
       " 'Lebensjahr': 13515,\n",
       " '##kontroll': 16510,\n",
       " '0': 1131,\n",
       " 'angenommen': 5008,\n",
       " 'Behandlung': 4902,\n",
       " 'verrät': 21159,\n",
       " 'Gallen': 19605,\n",
       " '##stöße': 13339,\n",
       " 'Weiterbildung': 19444,\n",
       " 'Komitee': 23451,\n",
       " '##13': 3414,\n",
       " 'Freundes': 19927,\n",
       " '##vid': 19820,\n",
       " '[unused4]': 27003,\n",
       " 'politischer': 11998,\n",
       " '[unused1031]': 28030,\n",
       " 'arbeitslos': 26843,\n",
       " '##inde': 1618,\n",
       " 'Zä': 12104,\n",
       " 'blaue': 24940,\n",
       " 'jungen': 4882,\n",
       " 'Anhieb': 26614,\n",
       " 'gegründeten': 8216,\n",
       " 'RTL': 13610,\n",
       " 'tritt': 5839,\n",
       " 'zusammenge': 12886,\n",
       " 'hofft': 16607,\n",
       " 'Thal': 17851,\n",
       " 'Buches': 13851,\n",
       " '##stuf': 11341,\n",
       " 'Miner': 16408,\n",
       " '##enseits': 11881,\n",
       " 'abgelehnt': 6549,\n",
       " 'Südkorea': 17656,\n",
       " '##,00': 5947,\n",
       " '##ierende': 4324,\n",
       " '##sächsischen': 13063,\n",
       " '##omotiven': 19737,\n",
       " 'wird': 292,\n",
       " 'Bekannt': 5287,\n",
       " '[unused2091]': 29090,\n",
       " 'Blog': 17812,\n",
       " 'Leuten': 16107,\n",
       " 'verlange': 15042,\n",
       " '##ames': 4252,\n",
       " '[unused824]': 27823,\n",
       " 'Anhang': 13914,\n",
       " 'Songs': 10412,\n",
       " '[unused990]': 27989,\n",
       " '##dition': 15175,\n",
       " '##ssen': 9781,\n",
       " 'steiger': 12417,\n",
       " '##ragen': 4620,\n",
       " '##uge': 16070,\n",
       " '##omet': 9854,\n",
       " 'englische': 10987,\n",
       " '##ett': 707,\n",
       " 'Bischöfe': 22392,\n",
       " 'fördert': 22514,\n",
       " '##zeilen': 18226,\n",
       " 'Ber': 298,\n",
       " '##ssystem': 8765,\n",
       " 'Lock': 22158,\n",
       " 'Unterstützer': 25636,\n",
       " 'Gegenstands': 23881,\n",
       " '##innend': 20956,\n",
       " 'Komposition': 13907,\n",
       " '##yd': 3682,\n",
       " '[unused1042]': 28041,\n",
       " '##usch': 4906,\n",
       " 'Händen': 13445,\n",
       " '[unused1837]': 28836,\n",
       " 'kreu': 24000,\n",
       " 'behalten': 13979,\n",
       " '##ussion': 23814,\n",
       " 'bzw': 1372,\n",
       " '##rypt': 18856,\n",
       " 'Zuerkennung': 26131,\n",
       " '##ersön': 2347,\n",
       " 'behauptet': 7504,\n",
       " 'Unterbringung': 14021,\n",
       " '[unused438]': 27437,\n",
       " 'Transfer': 16196,\n",
       " 'sowohl': 2772,\n",
       " '##Aff': 19000,\n",
       " 'bewe': 7516,\n",
       " '##stück': 1544,\n",
       " '##abet': 10937,\n",
       " '##olith': 18953,\n",
       " 'förm': 17326,\n",
       " '[unused2877]': 29876,\n",
       " 'öffentliches': 22924,\n",
       " 'wo': 743,\n",
       " '##abwehr': 14947,\n",
       " '##verbind': 16491,\n",
       " '[unused559]': 27558,\n",
       " '##ather': 20593,\n",
       " 'gebaute': 23052,\n",
       " '##erkloster': 26840,\n",
       " '[unused1574]': 28573,\n",
       " '##weile': 4336,\n",
       " '##enne': 15037,\n",
       " 'Män': 2121,\n",
       " '##brauch': 6894,\n",
       " 'langsam': 8061,\n",
       " 'Dank': 11129,\n",
       " '[unused2915]': 29914,\n",
       " '[unused2092]': 29091,\n",
       " '##hörde': 2793,\n",
       " 'beurteilt': 16315,\n",
       " 'Selbstver': 17876,\n",
       " 'Bas': 1890,\n",
       " '##mittag': 6887,\n",
       " '##älte': 13472,\n",
       " '##nachläss': 17910,\n",
       " '##leiter': 4342,\n",
       " 'trugen': 14167,\n",
       " 'studieren': 16424,\n",
       " 'Anschlägen': 24070,\n",
       " 'Bio': 11401,\n",
       " 'Aires': 18831,\n",
       " 'Kri': 17172,\n",
       " '##ension': 21365,\n",
       " '##mannschaften': 15022,\n",
       " '1927': 8438,\n",
       " '##pflichtigen': 10743,\n",
       " 'Ärger': 16434,\n",
       " '##rtung': 16276,\n",
       " '##fort': 2771,\n",
       " '[unused814]': 27813,\n",
       " 'Bach': 4510,\n",
       " 'Erwerber': 23251,\n",
       " 'zusätzlichen': 10388,\n",
       " 'Hongkong': 19237,\n",
       " '##dens': 4639,\n",
       " 'Software': 8004,\n",
       " '##6,': 2323,\n",
       " '##ußern': 13597,\n",
       " '##ish': 4753,\n",
       " '##bran': 8034,\n",
       " 'Kosten': 1314,\n",
       " 'Gerichtshofs': 15499,\n",
       " 'Zwie': 18914,\n",
       " '##protokoll': 21496,\n",
       " 'verhält': 20573,\n",
       " '##/10,': 17319,\n",
       " 'neg': 6317,\n",
       " 'gehe': 7220,\n",
       " '##zw': 852,\n",
       " '##aissance': 11953,\n",
       " '##Les': 22655,\n",
       " '[unused1988]': 28987,\n",
       " 'München': 1517,\n",
       " '##witz': 7936,\n",
       " 'ägyptischen': 23716,\n",
       " 'netto': 21093,\n",
       " 'Hills': 26870,\n",
       " 'städtische': 20583,\n",
       " 'insofern': 12444,\n",
       " '##Erst': 14616,\n",
       " 'Einkünften': 21060,\n",
       " 'verbindlich': 21924,\n",
       " 'Rumänien': 12588,\n",
       " 'Friedens': 11757,\n",
       " '[unused2296]': 29295,\n",
       " '##regionen': 22131,\n",
       " '##essor': 2857,\n",
       " 'Zulässigkeit': 13268,\n",
       " '##uert': 5667,\n",
       " '[unused1930]': 28929,\n",
       " '##leute': 7586,\n",
       " 'vorher': 4170,\n",
       " 'Erwachsenen': 14145,\n",
       " '##olische': 24297,\n",
       " '[unused48]': 27047,\n",
       " '[unused1349]': 28348,\n",
       " 'grundsätzlichen': 21007,\n",
       " '[unused1940]': 28939,\n",
       " '##sek': 18182,\n",
       " '##bedarfs': 20218,\n",
       " '##Kar': 16109,\n",
       " '[unused1577]': 28576,\n",
       " 'umbenannt': 8842,\n",
       " 'Neure': 18113,\n",
       " '##nette': 24642,\n",
       " 'Powiat': 23217,\n",
       " 'Aufregung': 25559,\n",
       " 'einstweiligen': 11895,\n",
       " 'Jahren': 605,\n",
       " 'musikalische': 16501,\n",
       " 'Pastor': 18889,\n",
       " 'subjekt': 12224,\n",
       " 'Verkehr': 2132,\n",
       " 'kamen': 3484,\n",
       " 'enorme': 26622,\n",
       " '##heit': 484,\n",
       " 'bringt': 6076,\n",
       " '##ope': 12090,\n",
       " '##quert': 13612,\n",
       " 'Eingruppierung': 26125,\n",
       " '[unused1580]': 28579,\n",
       " 'Wohnraum': 20983,\n",
       " 'Katal': 17128,\n",
       " 'italienische': 9631,\n",
       " '##wurzel': 23212,\n",
       " '[unused2066]': 29065,\n",
       " '##ringt': 4295,\n",
       " '[unused2967]': 29966,\n",
       " '##hnen': 2830,\n",
       " 'Ablauf': 5881,\n",
       " 'Alex': 3287,\n",
       " 'Nov': 7627,\n",
       " 'Anwalts': 24026,\n",
       " 'geboren': 2626,\n",
       " '!': 26982,\n",
       " 'Kraft': 2766,\n",
       " 'Dpartem': 6495,\n",
       " '##schall': 11690,\n",
       " 'mutmaßliche': 24097,\n",
       " 'Einsätze': 14471,\n",
       " 'durchgeführte': 23497,\n",
       " '##ittert': 22983,\n",
       " '##scheinlich': 3694,\n",
       " 'Kamer': 5010,\n",
       " '##ätzungen': 13605,\n",
       " '[unused2924]': 29923,\n",
       " '##HL': 8840,\n",
       " 'Thüringen': 10674,\n",
       " 'Restaurierung': 22282,\n",
       " '##bert': 1429,\n",
       " 'Bronzemedaille': 13655,\n",
       " 'Herren': 5081,\n",
       " '##lings': 6371,\n",
       " 'Inner': 5517,\n",
       " '##schreiber': 17080,\n",
       " '##reif': 6589,\n",
       " '[unused2688]': 29687,\n",
       " '[unused1242]': 28241,\n",
       " 'Cover': 16207,\n",
       " 'Halte': 10573,\n",
       " '##sthet': 14493,\n",
       " '##hologie': 14224,\n",
       " 'gefordert': 10503,\n",
       " 'besonderen': 5821,\n",
       " 'Stelle': 3080,\n",
       " '##chten': 2144,\n",
       " 'Angelegenheiten': 12936,\n",
       " '##ulgar': 7750,\n",
       " 'Bundespräsident': 19061,\n",
       " 'ab': 281,\n",
       " 'Bis': 1962,\n",
       " 'Amerikan': 16581,\n",
       " 'Ziele': 7874,\n",
       " 'HGB': 20150,\n",
       " '##vereinigung': 11197,\n",
       " '[unused1197]': 28196,\n",
       " 'Nato': 14761,\n",
       " '##abbau': 17991,\n",
       " 'Füßen': 22030,\n",
       " '[unused1407]': 28406,\n",
       " 'Gottes': 5921,\n",
       " 'pers': 23056,\n",
       " 'einziger': 13555,\n",
       " '##iaten': 25095,\n",
       " '##sex': 8327,\n",
       " 'Verkä': 12242,\n",
       " '650': 24468,\n",
       " '2006': 1612,\n",
       " '##historiker': 16473,\n",
       " 'Erzähl': 7928,\n",
       " 'Ins': 2024,\n",
       " 'Vorsorge': 21260,\n",
       " 'umgestaltet': 25010,\n",
       " 'Schr': 26081,\n",
       " 'zustande': 12593,\n",
       " '##cent': 15115,\n",
       " 'einzelne': 6441,\n",
       " '2018': 3265,\n",
       " 'Tau': 13835,\n",
       " '##gru': 11716,\n",
       " 'Verpflichtungen': 14162,\n",
       " 'Lärm': 9960,\n",
       " '##schauen': 15199,\n",
       " '[unused1282]': 28281,\n",
       " 'ebenso': 3006,\n",
       " 'Prei': 20066,\n",
       " 'Übersetzer': 22334,\n",
       " 'zugrunde': 5128,\n",
       " '##erkannt': 20858,\n",
       " 'wöchent': 20396,\n",
       " '##zurechnen': 11973,\n",
       " 'deutsche': 2006,\n",
       " 'Himmels': 20430,\n",
       " 'überwinden': 21047,\n",
       " '##opul': 25598,\n",
       " '[unused2477]': 29476,\n",
       " '[unused1343]': 28342,\n",
       " '##höhe': 5631,\n",
       " '##umstände': 25062,\n",
       " 'Charter': 26163,\n",
       " 'Betroffen': 9105,\n",
       " '[unused378]': 27377,\n",
       " '##kehrungen': 8735,\n",
       " 'Daniel': 7573,\n",
       " '[unused1020]': 28019,\n",
       " 'streiten': 12221,\n",
       " '##ires': 16141,\n",
       " '##gebende': 19907,\n",
       " '##wechs': 7423,\n",
       " '##sche': 1065,\n",
       " 'benutz': 16004,\n",
       " 'verbrachte': 9727,\n",
       " 'Kaufvertrag': 24802,\n",
       " '##Beschluss': 12206,\n",
       " 'meistens': 12234,\n",
       " '##geheim': 17341,\n",
       " 'unmittel': 3105,\n",
       " 'Maurer': 25402,\n",
       " '##echs': 15970,\n",
       " '##aufsicht': 11685,\n",
       " '##ster': 245,\n",
       " '##Schw': 19804,\n",
       " '##iffe': 25296,\n",
       " 'vorliegend': 6322,\n",
       " 'Praxis': 6016,\n",
       " '##wetter': 18542,\n",
       " '[unused1839]': 28838,\n",
       " 'schaut': 18322,\n",
       " 'Begriff': 2940,\n",
       " '##fähigkeit': 3907,\n",
       " 'Platz': 1361,\n",
       " '##these': 15820,\n",
       " 'Einholung': 23504,\n",
       " '##Y': 26974,\n",
       " 'Kenntnisse': 13623,\n",
       " 'Gor': 16556,\n",
       " '##hältnis': 1289,\n",
       " 'gefährlichen': 23095,\n",
       " 'Pil': 4765,\n",
       " 'fragte': 17933,\n",
       " '[unused804]': 27803,\n",
       " '11.': 2463,\n",
       " 'Mad': 4488,\n",
       " 'Explosion': 18665,\n",
       " 'Inszenierung': 18841,\n",
       " 'Sitzungs': 18092,\n",
       " 'fikt': 13220,\n",
       " '##klich': 4050,\n",
       " '[unused609]': 27608,\n",
       " 'ök': 13236,\n",
       " '##unden': 592,\n",
       " '##former': 22445,\n",
       " '[unused2998]': 29997,\n",
       " 'stamm': 7649,\n",
       " '##sturz': 11630,\n",
       " '##finanz': 6548,\n",
       " '##arischer': 18484,\n",
       " '1865': 15972,\n",
       " '##Ac': 20538,\n",
       " 'Zimmer': 7135,\n",
       " '##ömm': 12578,\n",
       " 'Lindner': 26599,\n",
       " 'Verfahren': 2259,\n",
       " '##abschnitt': 10952,\n",
       " 'Freiheitsstrafe': 17764,\n",
       " 'Lug': 23068,\n",
       " '§80': 18259,\n",
       " 'Reihen': 7764,\n",
       " '189': 2158,\n",
       " '[unused1196]': 28195,\n",
       " 'Potsdamer': 23566,\n",
       " 'vereinbarte': 17793,\n",
       " '##zins': 11937,\n",
       " 'literarischen': 18154,\n",
       " 'zugestimmt': 21336,\n",
       " 'erbr': 11482,\n",
       " '[unused2126]': 29125,\n",
       " 'besp': 23306,\n",
       " '##olph': 16369,\n",
       " 'Rüst': 14892,\n",
       " 'Rud': 5262,\n",
       " '[unused2761]': 29760,\n",
       " '[unused2075]': 29074,\n",
       " '[unused1383]': 28382,\n",
       " 'Pau': 8092,\n",
       " 'umgewandelt': 13697,\n",
       " '##arg': 23860,\n",
       " 'Gleiches': 17943,\n",
       " '[unused973]': 27972,\n",
       " 'Häuser': 6800,\n",
       " '##ualen': 23600,\n",
       " '##sparen': 16237,\n",
       " '##Min': 10363,\n",
       " 'Respekt': 15680,\n",
       " 'gescheitert': 14609,\n",
       " 'Seminar': 16855,\n",
       " '##einsatz': 10511,\n",
       " 'Anhängern': 23532,\n",
       " 'Indien': 8458,\n",
       " '##ärs': 23889,\n",
       " 'Steffen': 23691,\n",
       " '##dist': 25065,\n",
       " 'Kün': 2913,\n",
       " '##kle': 18197,\n",
       " '##refer': 14432,\n",
       " '[unused2087]': 29086,\n",
       " '##/14,': 20626,\n",
       " '##reihe': 10132,\n",
       " '##eigt': 1498,\n",
       " 'selben': 4469,\n",
       " 'Andrew': 18595,\n",
       " 'bedro': 7849,\n",
       " 'Rundfunks': 22950,\n",
       " '##hoben': 2159,\n",
       " '[unused1503]': 28502,\n",
       " 'Lord': 14775,\n",
       " 'Nikol': 9386,\n",
       " 'Ruß': 25640,\n",
       " 'gekennzeichnet': 12881,\n",
       " 'Stasi': 23353,\n",
       " 'neuer': 4201,\n",
       " '[unused502]': 27501,\n",
       " '[unused1607]': 28606,\n",
       " 'schwier': 5352,\n",
       " 'sowjetischen': 11798,\n",
       " 'Behinderten': 26791,\n",
       " 'internationaler': 14830,\n",
       " '##mechan': 13040,\n",
       " '##rahmen': 14199,\n",
       " 'Einschätzung': 8180,\n",
       " 'Fahrzeuge': 6319,\n",
       " 'Testaments': 24661,\n",
       " '##alters': 15899,\n",
       " 'Verleger': 14969,\n",
       " '[unused2684]': 29683,\n",
       " '[unused2540]': 29539,\n",
       " 'betroffene': 22575,\n",
       " 'Tex': 5148,\n",
       " 'vorgeworfen': 12440,\n",
       " '##räsid': 8304,\n",
       " 'Konkurs': 26796,\n",
       " '##ipel': 18617,\n",
       " 'Europ': 1074,\n",
       " '[unused35]': 27034,\n",
       " '##Gro': 10788,\n",
       " 'bezeichnen': 13042,\n",
       " 'Abzug': 11842,\n",
       " '##oga': 20219,\n",
       " '##iac': 25389,\n",
       " 'bra': 9750,\n",
       " '[unused638]': 27637,\n",
       " 'folgt': 2872,\n",
       " 'Probe': 11547,\n",
       " '##ähnliche': 25286,\n",
       " 'Kassen': 11161,\n",
       " 'Gehirn': 14813,\n",
       " '##ulabschluss': 22280,\n",
       " '€.': 15853,\n",
       " 'dazwischen': 22241,\n",
       " 'damalige': 8640,\n",
       " '2004,': 11214,\n",
       " '##ena': 4749,\n",
       " 'Fell': 10351,\n",
       " 'solche': 2264,\n",
       " '##hte': 3857,\n",
       " 'geform': 21158,\n",
       " '##kritiker': 22415,\n",
       " 'gesetzgeber': 25779,\n",
       " '##schild': 12136,\n",
       " 'Us': 23515,\n",
       " '[unused1405]': 28404,\n",
       " 'auszugehen': 7293,\n",
       " 'urteil': 18987,\n",
       " 'Stahl': 6751,\n",
       " 'beziff': 23373,\n",
       " '##reuen': 9901,\n",
       " 'Berichter': 11597,\n",
       " 'Empfänger': 12986,\n",
       " 'stattgegeben': 19458,\n",
       " '##GH': 2273,\n",
       " 'Monika': 23295,\n",
       " '##griffen': 3514,\n",
       " 'pass': 5156,\n",
       " '##äfts': 12584,\n",
       " 'Jahrhundert': 1256,\n",
       " '##stal': 20462,\n",
       " 'Berechnungen': 19456,\n",
       " '##otheken': 21040,\n",
       " 'Tam': 17524,\n",
       " '##ften': 548,\n",
       " '##ografen': 16026,\n",
       " 'Kali': 20188,\n",
       " '##erk': 600,\n",
       " 'Heim': 2104,\n",
       " 'Beigeladen': 4203,\n",
       " '##Mode': 20009,\n",
       " '##ienst': 771,\n",
       " 'drückt': 24612,\n",
       " 'Draht': 21172,\n",
       " '1100': 26115,\n",
       " '##missbrauch': 21498,\n",
       " 'geplant': 6290,\n",
       " 'soweit': 4133,\n",
       " 'abgewiesen': 7530,\n",
       " '1836': 20968,\n",
       " 'Oder': 7774,\n",
       " 'Wirt': 19970,\n",
       " '##gewährung': 24101,\n",
       " '##atch': 17094,\n",
       " '##slos': 20905,\n",
       " 'konstant': 24515,\n",
       " '[unused1844]': 28843,\n",
       " 'oberhalb': 10996,\n",
       " '##reiben': 1537,\n",
       " '##ilden': 20080,\n",
       " '##iness': 13440,\n",
       " '##atoren': 7193,\n",
       " '##iziert': 5786,\n",
       " '##lässige': 25191,\n",
       " '##gart': 4191,\n",
       " 'Mär': 7215,\n",
       " '[unused2746]': 29745,\n",
       " 'holt': 20611,\n",
       " 'Lim': 7068,\n",
       " '[unused1893]': 28892,\n",
       " '##teil': 440,\n",
       " '##arett': 13428,\n",
       " 'fließt': 8808,\n",
       " 'seines': 1688,\n",
       " 'Schu': 5818,\n",
       " 'McCart': 26746,\n",
       " '##LB': 20768,\n",
       " 'verlor': 5353,\n",
       " '##ird': 9098,\n",
       " 'unterteilt': 14810,\n",
       " 'Profession': 25098,\n",
       " '##iens': 4059,\n",
       " '[unused2307]': 29306,\n",
       " 'entsprechendes': 25652,\n",
       " 'pla': 21393,\n",
       " 'normalen': 12669,\n",
       " '##lia': 24183,\n",
       " 'Wal': 4527,\n",
       " '##politiker': 17548,\n",
       " '[unused1931]': 28930,\n",
       " '[unused2763]': 29762,\n",
       " '##di': 3748,\n",
       " 'Nachfol': 23919,\n",
       " 'Camp': 6499,\n",
       " '##kurz': 21310,\n",
       " 'Bundesagentur': 24214,\n",
       " '##hm': 501,\n",
       " 'Korn': 15095,\n",
       " 'Berliner': 2586,\n",
       " '##law': 5768,\n",
       " '##za': 4936,\n",
       " '##arburg': 10816,\n",
       " 'Bol': 8797,\n",
       " '31.12': 13647,\n",
       " 'orts': 18702,\n",
       " 'Fur': 11849,\n",
       " 'Graben': 14297,\n",
       " 'fährt': 9755,\n",
       " 'Schaff': 24138,\n",
       " 'Gläubiger': 10048,\n",
       " '##irn': 5053,\n",
       " '##garn': 6154,\n",
       " '##folge': 2571,\n",
       " 'Janeiro': 18329,\n",
       " 'Südseite': 19655,\n",
       " 'landwirtschaft': 7157,\n",
       " 'Traum': 7948,\n",
       " 'Mov': 23209,\n",
       " 'Treibst': 23864,\n",
       " '1824': 22259,\n",
       " 'materiellen': 13690,\n",
       " '##össer': 26242,\n",
       " '[unused2190]': 29189,\n",
       " '[unused989]': 27988,\n",
       " 'kar': 17078,\n",
       " 'Erscheinen': 20910,\n",
       " '##sson': 10222,\n",
       " '##lassung': 4569,\n",
       " '##reue': 18731,\n",
       " 'Haltepunkt': 22072,\n",
       " '##Lo': 23796,\n",
       " 'Stolper': 26309,\n",
       " 'Dieses': 3598,\n",
       " 'regelt': 15494,\n",
       " 'Armuts': 23623,\n",
       " '##verteidiger': 11604,\n",
       " 'Kanonen': 26863,\n",
       " '##hoe': 17767,\n",
       " '##kauft': 8361,\n",
       " '##ti': 15099,\n",
       " 'achte': 21376,\n",
       " 'Mehrwert': 15084,\n",
       " 'Erholung': 22971,\n",
       " 'rechteck': 16935,\n",
       " 'großes': 7309,\n",
       " 'kämen': 21546,\n",
       " 'Mehrheit': 6088,\n",
       " '##aha': 25377,\n",
       " '##ierte': 456,\n",
       " 'Häu': 21538,\n",
       " 'Quote': 22385,\n",
       " '##sonsten': 8573,\n",
       " '##asser': 899,\n",
       " 'staat': 2776,\n",
       " 'Sü': 2611,\n",
       " '##folgt': 9484,\n",
       " 'offizielle': 10592,\n",
       " 'Western': 14016,\n",
       " 'Cher': 19393,\n",
       " '[unused2224]': 29223,\n",
       " 'Unentschieden': 23076,\n",
       " '##ausfall': 20801,\n",
       " '[unused2282]': 29281,\n",
       " 'Protokoll': 10252,\n",
       " 'Verstorbenen': 26286,\n",
       " 'derer': 14877,\n",
       " 'hl': 22382,\n",
       " 'verfol': 4311,\n",
       " 'Anzahl': 5039,\n",
       " 'sportlichen': 18966,\n",
       " '53': 9244,\n",
       " '##halb': 692,\n",
       " '##ohlen': 6954,\n",
       " 'Sauer': 9878,\n",
       " '##wG': 2123,\n",
       " 'angezeigt': 16350,\n",
       " 'Hiergegen': 22252,\n",
       " '[unused2965]': 29964,\n",
       " '##burg': 599,\n",
       " 'Trink': 9119,\n",
       " '##ächter': 12114,\n",
       " 'verstehen': 6661,\n",
       " 'innere': 14487,\n",
       " 'den': 86,\n",
       " 'gelangten': 24077,\n",
       " '##garten': 5579,\n",
       " 'J': 112,\n",
       " 'Wisconsin': 24882,\n",
       " '[unused2995]': 29994,\n",
       " 'elekt': 4079,\n",
       " '##auto': 26805,\n",
       " 'Mi': 9345,\n",
       " 'Nation': 4738,\n",
       " '##EP': 19941,\n",
       " 'Skulpturen': 17889,\n",
       " 'form': 1648,\n",
       " 'Fass': 7228,\n",
       " 'Zustimmung': 6990,\n",
       " 'Spielfilm': 15940,\n",
       " 'Böden': 21470,\n",
       " 'Verordnung': 4688,\n",
       " 'Stifter': 25916,\n",
       " 'Stadtverwaltung': 21454,\n",
       " '##itat': 20630,\n",
       " '[unused2372]': 29371,\n",
       " 'Firma': 3770,\n",
       " '1974': 5377,\n",
       " 'Boule': 18915,\n",
       " '##udium': 18974,\n",
       " '##Johann': 22023,\n",
       " 'Fenstern': 24454,\n",
       " '[unused682]': 27681,\n",
       " ...}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T12:15:33.527028Z",
     "start_time": "2024-09-14T12:15:33.522229Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.vocab_size",
   "id": "6d1210237436891b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T12:15:42.056815Z",
     "start_time": "2024-09-14T12:15:42.054078Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.vocab_files_names",
   "id": "6079cd646a96528d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_file': 'vocab.txt', 'tokenizer_file': 'tokenizer.json'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T12:20:37.837756Z",
     "start_time": "2024-09-14T12:20:37.826620Z"
    }
   },
   "cell_type": "code",
   "source": "dir(tokenizer)",
   "id": "feb5f3111973a7b0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SPECIAL_TOKENS_ATTRIBUTES',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_tokens',\n",
       " '_additional_special_tokens',\n",
       " '_auto_class',\n",
       " '_batch_encode_plus',\n",
       " '_bos_token',\n",
       " '_call_one',\n",
       " '_cls_token',\n",
       " '_compile_jinja_template',\n",
       " '_convert_encoding',\n",
       " '_convert_id_to_token',\n",
       " '_convert_token_to_id_with_added_voc',\n",
       " '_create_repo',\n",
       " '_decode',\n",
       " '_decode_use_source_tokenizer',\n",
       " '_encode_plus',\n",
       " '_eos_token',\n",
       " '_eventual_warn_about_too_long_sequence',\n",
       " '_eventually_correct_t5_max_length',\n",
       " '_from_pretrained',\n",
       " '_get_files_timestamps',\n",
       " '_get_padding_truncation_strategies',\n",
       " '_in_target_context_manager',\n",
       " '_mask_token',\n",
       " '_pad',\n",
       " '_pad_token',\n",
       " '_pad_token_type_id',\n",
       " '_processor_class',\n",
       " '_render_with_assistant_indices',\n",
       " '_save_pretrained',\n",
       " '_sep_token',\n",
       " '_set_processor_class',\n",
       " '_switch_to_input_mode',\n",
       " '_switch_to_target_mode',\n",
       " '_tokenizer',\n",
       " '_unk_token',\n",
       " '_upload_modified_files',\n",
       " 'add_special_tokens',\n",
       " 'add_tokens',\n",
       " 'added_tokens_decoder',\n",
       " 'added_tokens_encoder',\n",
       " 'additional_special_tokens',\n",
       " 'additional_special_tokens_ids',\n",
       " 'all_special_ids',\n",
       " 'all_special_tokens',\n",
       " 'all_special_tokens_extended',\n",
       " 'apply_chat_template',\n",
       " 'as_target_tokenizer',\n",
       " 'backend_tokenizer',\n",
       " 'batch_decode',\n",
       " 'batch_encode_plus',\n",
       " 'bos_token',\n",
       " 'bos_token_id',\n",
       " 'build_inputs_with_special_tokens',\n",
       " 'can_save_slow_tokenizer',\n",
       " 'chat_template',\n",
       " 'clean_up_tokenization',\n",
       " 'clean_up_tokenization_spaces',\n",
       " 'cls_token',\n",
       " 'cls_token_id',\n",
       " 'convert_added_tokens',\n",
       " 'convert_ids_to_tokens',\n",
       " 'convert_tokens_to_ids',\n",
       " 'convert_tokens_to_string',\n",
       " 'create_token_type_ids_from_sequences',\n",
       " 'decode',\n",
       " 'decoder',\n",
       " 'deprecation_warnings',\n",
       " 'do_lower_case',\n",
       " 'encode',\n",
       " 'encode_plus',\n",
       " 'eos_token',\n",
       " 'eos_token_id',\n",
       " 'from_pretrained',\n",
       " 'get_added_vocab',\n",
       " 'get_chat_template',\n",
       " 'get_special_tokens_mask',\n",
       " 'get_vocab',\n",
       " 'init_inputs',\n",
       " 'init_kwargs',\n",
       " 'is_fast',\n",
       " 'mask_token',\n",
       " 'mask_token_id',\n",
       " 'max_len_sentences_pair',\n",
       " 'max_len_single_sentence',\n",
       " 'model_input_names',\n",
       " 'model_max_length',\n",
       " 'name_or_path',\n",
       " 'num_special_tokens_to_add',\n",
       " 'pad',\n",
       " 'pad_token',\n",
       " 'pad_token_id',\n",
       " 'pad_token_type_id',\n",
       " 'padding_side',\n",
       " 'prepare_for_model',\n",
       " 'prepare_seq2seq_batch',\n",
       " 'pretrained_vocab_files_map',\n",
       " 'push_to_hub',\n",
       " 'register_for_auto_class',\n",
       " 'sanitize_special_tokens',\n",
       " 'save_pretrained',\n",
       " 'save_vocabulary',\n",
       " 'sep_token',\n",
       " 'sep_token_id',\n",
       " 'set_truncation_and_padding',\n",
       " 'slow_tokenizer_class',\n",
       " 'special_tokens_map',\n",
       " 'special_tokens_map_extended',\n",
       " 'split_special_tokens',\n",
       " 'tokenize',\n",
       " 'train_new_from_iterator',\n",
       " 'truncate_sequences',\n",
       " 'truncation_side',\n",
       " 'unk_token',\n",
       " 'unk_token_id',\n",
       " 'verbose',\n",
       " 'vocab',\n",
       " 'vocab_files_names',\n",
       " 'vocab_size']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T12:20:53.704763Z",
     "start_time": "2024-09-14T12:20:53.695066Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.verbose",
   "id": "6e686be75ff17f71",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T12:27:01.463581Z",
     "start_time": "2024-09-14T12:27:01.315903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, BertModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 示例数据\n",
    "texts = [\n",
    "    \"I love programming in Python\",\n",
    "    \"Python is a great language\",\n",
    "    \"Programming is fun\"\n",
    "]\n",
    "labels = [1, 1, 0]  # 假设 1 表示正面评价，0 表示负面评价\n",
    "\n",
    "# 加载预训练的分词器和模型\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../.pretrained_models/bert-base-cased\")\n",
    "model = BertModel.from_pretrained(\"../.pretrained_models/bert-base-cased\")\n",
    "\n",
    "\n",
    "# 定义数据集类\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=10):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # 使用分词器进行分词和编码\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        input_ids = encoding['input_ids'].squeeze(0)\n",
    "        attention_mask = encoding['attention_mask'].squeeze(0)\n",
    "\n",
    "        return input_ids, attention_mask, torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "\n",
    "# 创建数据集\n",
    "dataset = TextDataset(texts, labels, tokenizer)\n",
    "\n",
    "# 创建数据加载器\n",
    "batch_size = 2\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 打印数据集中的一个批次\n",
    "for batch in data_loader:\n",
    "    input_ids, attention_mask, targets = batch\n",
    "    print(\"Input IDs:\", input_ids)\n",
    "    print(\"Attention Mask:\", attention_mask)\n",
    "    print(\"Targets:\", targets)\n",
    "    break\n",
    "\n",
    "\n",
    "# 获取句子的嵌入表示\n",
    "def get_sentence_embeddings(texts, tokenizer, model):\n",
    "    # 分词和编码\n",
    "    encoding = tokenizer(texts, truncation=True, padding=True, return_tensors='pt')\n",
    "    input_ids = encoding['input_ids']\n",
    "    attention_mask = encoding['attention_mask']\n",
    "\n",
    "    # 获取模型输出\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)  # 取平均作为句子嵌入\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "# 获取示例文本的嵌入表示\n",
    "sentence_embeddings = get_sentence_embeddings(texts, tokenizer, model)\n",
    "print(\"Sentence Embeddings:\")\n",
    "print(sentence_embeddings)\n"
   ],
   "id": "616c5ca3ede13c62",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/new_home/xzj23/.conda/envs/slr/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: tensor([[  101, 21076,  1110,  4106,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,   146,  1567,  4159,  1107, 23334,   102,     0,     0,     0]])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])\n",
      "Targets: tensor([0., 1.])\n",
      "{'input_ids': tensor([[  101,   146,  1567,  4159,  1107, 23334,   102],\n",
      "        [  101, 23334,  1110,   170,  1632,  1846,   102],\n",
      "        [  101, 21076,  1110,  4106,   102,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 0, 0]])}\n",
      "Sentence Embeddings:\n",
      "tensor([[ 0.4559,  0.1651, -0.2481,  ...,  0.2512,  0.1600,  0.2613],\n",
      "        [ 0.6230,  0.0513, -0.2029,  ...,  0.1886,  0.0581,  0.2735],\n",
      "        [ 0.4072,  0.1323,  0.2236,  ...,  0.0941,  0.3853,  0.3177]])\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T12:24:19.928442Z",
     "start_time": "2024-09-14T12:24:19.915890Z"
    }
   },
   "cell_type": "code",
   "source": "sentence_embeddings",
   "id": "752d0a81a405f8d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4559,  0.1651, -0.2481,  ...,  0.2512,  0.1600,  0.2613],\n",
       "        [ 0.6230,  0.0513, -0.2029,  ...,  0.1886,  0.0581,  0.2735],\n",
       "        [ 0.4072,  0.1323,  0.2236,  ...,  0.0941,  0.3853,  0.3177]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T12:24:26.613193Z",
     "start_time": "2024-09-14T12:24:26.604314Z"
    }
   },
   "cell_type": "code",
   "source": "sentence_embeddings.shape",
   "id": "3b6f2abb74e05ed3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 768])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T12:32:37.567222Z",
     "start_time": "2024-09-14T12:32:37.387032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, BertModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 示例数据\n",
    "texts = [\n",
    "    \"I love programming in Python\",\n",
    "    \"Python is a great language\",\n",
    "    \"Programming is fun\"\n",
    "]\n",
    "labels = [1, 1, 0]  # 假设 1 表示正面评价，0 表示负面评价\n",
    "\n",
    "# 加载预训练的分词器和模型\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../.pretrained_models/bert-base-cased\")\n",
    "model = BertModel.from_pretrained(\"../.pretrained_models/bert-base-cased\")\n",
    "\n",
    "\n",
    "# 定义数据集类\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=10):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # 使用分词器进行分词和编码\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        input_ids = encoding['input_ids'].squeeze(0)\n",
    "        attention_mask = encoding['attention_mask'].squeeze(0)\n",
    "\n",
    "        return input_ids, attention_mask, torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "\n",
    "# 创建数据集\n",
    "dataset = TextDataset(texts, labels, tokenizer)\n",
    "\n",
    "# 创建数据加载器\n",
    "batch_size = 2\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 打印数据集中的一个批次\n",
    "for batch in data_loader:\n",
    "    input_ids, attention_mask, targets = batch\n",
    "    print(\"Input IDs:\", input_ids)\n",
    "    print(\"Attention Mask:\", attention_mask)\n",
    "    print(\"Targets:\", targets)\n",
    "    break\n",
    "\n",
    "\n",
    "# 获取句子的词嵌入表示\n",
    "def get_word_embeddings(texts, tokenizer, model):\n",
    "    # 分词和编码\n",
    "    encoding = tokenizer(texts, truncation=True, padding=True, return_tensors='pt')\n",
    "    input_ids = encoding['input_ids']\n",
    "    attention_mask = encoding['attention_mask']\n",
    "\n",
    "    # 获取模型输出\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "\n",
    "    # 返回词嵌入表示\n",
    "    return last_hidden_state\n",
    "\n",
    "\n",
    "# 获取示例文本的词嵌入表示\n",
    "word_embeddings = get_word_embeddings(texts, tokenizer, model)\n",
    "print(\"Word Embeddings:\")\n",
    "print(word_embeddings)\n"
   ],
   "id": "2b027df4f59ebda5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: tensor([[  101, 23334,  1110,   170,  1632,  1846,   102,     0,     0,     0],\n",
      "        [  101,   146,  1567,  4159,  1107, 23334,   102,     0,     0,     0]])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])\n",
      "Targets: tensor([1., 1.])\n",
      "Word Embeddings:\n",
      "tensor([[[ 6.7468e-01,  6.9297e-02, -3.0896e-01,  ...,  9.4618e-02,\n",
      "           5.6142e-01,  1.9888e-01],\n",
      "         [ 3.1860e-01,  8.9978e-02,  2.0622e-01,  ...,  1.7626e-01,\n",
      "          -6.3275e-02,  5.5940e-01],\n",
      "         [ 1.3464e-01, -3.9309e-03, -4.9525e-01,  ...,  7.4246e-01,\n",
      "          -6.7457e-01,  2.4827e-01],\n",
      "         ...,\n",
      "         [ 1.3741e-01, -1.6979e-01,  1.4357e-02,  ...,  2.7694e-01,\n",
      "           2.7418e-01, -2.8970e-02],\n",
      "         [ 4.4751e-01,  1.5007e-01, -5.0931e-01,  ..., -2.3448e-02,\n",
      "           3.8850e-01,  2.9415e-01],\n",
      "         [ 1.1601e+00,  4.0479e-01, -7.0263e-01,  ...,  1.0551e-01,\n",
      "           9.0991e-01,  1.1078e-01]],\n",
      "\n",
      "        [[ 6.6111e-01, -4.5665e-02, -2.3723e-01,  ..., -2.1379e-01,\n",
      "           4.4178e-01,  1.8100e-01],\n",
      "         [ 1.3115e-01,  2.0537e-01, -1.1338e-01,  ...,  4.8119e-01,\n",
      "          -7.4567e-02,  1.3037e-01],\n",
      "         [ 6.0926e-01,  1.1605e-01, -1.5134e-01,  ..., -1.4685e-01,\n",
      "          -1.4565e-01,  2.7229e-01],\n",
      "         ...,\n",
      "         [ 3.5091e-01, -7.3922e-02, -2.8791e-01,  ...,  7.4428e-01,\n",
      "          -3.0240e-01,  7.6700e-01],\n",
      "         [ 5.2017e-01, -2.7451e-01,  8.7420e-02,  ...,  7.5306e-02,\n",
      "          -4.1772e-01, -4.9089e-02],\n",
      "         [ 1.4928e+00,  2.5827e-01, -2.4962e-01,  ...,  8.5693e-02,\n",
      "           1.0858e+00,  1.4752e-01]],\n",
      "\n",
      "        [[ 4.9129e-01,  9.9368e-04,  6.6753e-02,  ...,  2.4958e-02,\n",
      "           5.4598e-01,  2.4419e-01],\n",
      "         [ 3.9581e-01,  2.7902e-01,  5.0768e-01,  ...,  3.1988e-02,\n",
      "           2.8267e-02,  6.0232e-02],\n",
      "         [ 2.4782e-01, -4.4792e-02,  3.7834e-01,  ...,  2.2632e-01,\n",
      "           1.2512e-01,  5.3118e-01],\n",
      "         ...,\n",
      "         [ 1.0205e+00,  4.6588e-01,  2.2433e-01,  ...,  3.3880e-02,\n",
      "           1.3673e+00,  1.0694e-02],\n",
      "         [-6.9408e-02,  1.9883e-01,  2.5174e-02,  ...,  2.3744e-01,\n",
      "           3.1498e-01,  3.9405e-01],\n",
      "         [ 1.7794e-02,  1.9690e-02,  2.3908e-01,  ...,  2.8104e-01,\n",
      "           1.2856e-01,  3.7427e-01]]])\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T12:29:52.523591Z",
     "start_time": "2024-09-14T12:29:52.517807Z"
    }
   },
   "cell_type": "code",
   "source": "word_embeddings.shape",
   "id": "8f9280b7ae3ee66b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 7, 768])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T12:37:05.237987Z",
     "start_time": "2024-09-14T12:37:05.195252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import transformers\n",
    "dir(transformers)"
   ],
   "id": "7186eb02898b97e2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ASTConfig',\n",
       " 'ASTFeatureExtractor',\n",
       " 'ASTForAudioClassification',\n",
       " 'ASTModel',\n",
       " 'ASTPreTrainedModel',\n",
       " 'Adafactor',\n",
       " 'AdamW',\n",
       " 'AdamWeightDecay',\n",
       " 'AdaptiveEmbedding',\n",
       " 'AddedToken',\n",
       " 'Agent',\n",
       " 'AlbertConfig',\n",
       " 'AlbertForMaskedLM',\n",
       " 'AlbertForMultipleChoice',\n",
       " 'AlbertForPreTraining',\n",
       " 'AlbertForQuestionAnswering',\n",
       " 'AlbertForSequenceClassification',\n",
       " 'AlbertForTokenClassification',\n",
       " 'AlbertModel',\n",
       " 'AlbertPreTrainedModel',\n",
       " 'AlbertTokenizer',\n",
       " 'AlbertTokenizerFast',\n",
       " 'AlignConfig',\n",
       " 'AlignModel',\n",
       " 'AlignPreTrainedModel',\n",
       " 'AlignProcessor',\n",
       " 'AlignTextConfig',\n",
       " 'AlignTextModel',\n",
       " 'AlignVisionConfig',\n",
       " 'AlignVisionModel',\n",
       " 'AltCLIPConfig',\n",
       " 'AltCLIPModel',\n",
       " 'AltCLIPPreTrainedModel',\n",
       " 'AltCLIPProcessor',\n",
       " 'AltCLIPTextConfig',\n",
       " 'AltCLIPTextModel',\n",
       " 'AltCLIPVisionConfig',\n",
       " 'AltCLIPVisionModel',\n",
       " 'AlternatingCodebooksLogitsProcessor',\n",
       " 'AqlmConfig',\n",
       " 'AudioClassificationPipeline',\n",
       " 'AutoBackbone',\n",
       " 'AutoConfig',\n",
       " 'AutoFeatureExtractor',\n",
       " 'AutoImageProcessor',\n",
       " 'AutoModel',\n",
       " 'AutoModelForAudioClassification',\n",
       " 'AutoModelForAudioFrameClassification',\n",
       " 'AutoModelForAudioXVector',\n",
       " 'AutoModelForCTC',\n",
       " 'AutoModelForCausalLM',\n",
       " 'AutoModelForDepthEstimation',\n",
       " 'AutoModelForDocumentQuestionAnswering',\n",
       " 'AutoModelForImageClassification',\n",
       " 'AutoModelForImageSegmentation',\n",
       " 'AutoModelForImageToImage',\n",
       " 'AutoModelForInstanceSegmentation',\n",
       " 'AutoModelForKeypointDetection',\n",
       " 'AutoModelForMaskGeneration',\n",
       " 'AutoModelForMaskedImageModeling',\n",
       " 'AutoModelForMaskedLM',\n",
       " 'AutoModelForMultipleChoice',\n",
       " 'AutoModelForNextSentencePrediction',\n",
       " 'AutoModelForObjectDetection',\n",
       " 'AutoModelForPreTraining',\n",
       " 'AutoModelForQuestionAnswering',\n",
       " 'AutoModelForSemanticSegmentation',\n",
       " 'AutoModelForSeq2SeqLM',\n",
       " 'AutoModelForSequenceClassification',\n",
       " 'AutoModelForSpeechSeq2Seq',\n",
       " 'AutoModelForTableQuestionAnswering',\n",
       " 'AutoModelForTextEncoding',\n",
       " 'AutoModelForTextToSpectrogram',\n",
       " 'AutoModelForTextToWaveform',\n",
       " 'AutoModelForTokenClassification',\n",
       " 'AutoModelForUniversalSegmentation',\n",
       " 'AutoModelForVideoClassification',\n",
       " 'AutoModelForVision2Seq',\n",
       " 'AutoModelForVisualQuestionAnswering',\n",
       " 'AutoModelForZeroShotImageClassification',\n",
       " 'AutoModelForZeroShotObjectDetection',\n",
       " 'AutoModelWithLMHead',\n",
       " 'AutoProcessor',\n",
       " 'AutoTokenizer',\n",
       " 'AutoformerConfig',\n",
       " 'AutoformerForPrediction',\n",
       " 'AutoformerModel',\n",
       " 'AutoformerPreTrainedModel',\n",
       " 'AutomaticSpeechRecognitionPipeline',\n",
       " 'AwqConfig',\n",
       " 'BarkCausalModel',\n",
       " 'BarkCoarseConfig',\n",
       " 'BarkCoarseModel',\n",
       " 'BarkConfig',\n",
       " 'BarkFineConfig',\n",
       " 'BarkFineModel',\n",
       " 'BarkModel',\n",
       " 'BarkPreTrainedModel',\n",
       " 'BarkProcessor',\n",
       " 'BarkSemanticConfig',\n",
       " 'BarkSemanticModel',\n",
       " 'BartConfig',\n",
       " 'BartForCausalLM',\n",
       " 'BartForConditionalGeneration',\n",
       " 'BartForQuestionAnswering',\n",
       " 'BartForSequenceClassification',\n",
       " 'BartModel',\n",
       " 'BartPreTrainedModel',\n",
       " 'BartPretrainedModel',\n",
       " 'BartTokenizer',\n",
       " 'BartTokenizerFast',\n",
       " 'BarthezTokenizer',\n",
       " 'BarthezTokenizerFast',\n",
       " 'BartphoTokenizer',\n",
       " 'BaseImageProcessor',\n",
       " 'BaseImageProcessorFast',\n",
       " 'BasicTokenizer',\n",
       " 'BatchEncoding',\n",
       " 'BatchFeature',\n",
       " 'BeamScorer',\n",
       " 'BeamSearchScorer',\n",
       " 'BeitBackbone',\n",
       " 'BeitConfig',\n",
       " 'BeitFeatureExtractor',\n",
       " 'BeitForImageClassification',\n",
       " 'BeitForMaskedImageModeling',\n",
       " 'BeitForSemanticSegmentation',\n",
       " 'BeitImageProcessor',\n",
       " 'BeitModel',\n",
       " 'BeitPreTrainedModel',\n",
       " 'BertConfig',\n",
       " 'BertForMaskedLM',\n",
       " 'BertForMultipleChoice',\n",
       " 'BertForNextSentencePrediction',\n",
       " 'BertForPreTraining',\n",
       " 'BertForQuestionAnswering',\n",
       " 'BertForSequenceClassification',\n",
       " 'BertForTokenClassification',\n",
       " 'BertGenerationConfig',\n",
       " 'BertGenerationDecoder',\n",
       " 'BertGenerationEncoder',\n",
       " 'BertGenerationPreTrainedModel',\n",
       " 'BertGenerationTokenizer',\n",
       " 'BertJapaneseTokenizer',\n",
       " 'BertLMHeadModel',\n",
       " 'BertLayer',\n",
       " 'BertModel',\n",
       " 'BertPreTrainedModel',\n",
       " 'BertTokenizer',\n",
       " 'BertTokenizerFast',\n",
       " 'BertweetTokenizer',\n",
       " 'BigBirdConfig',\n",
       " 'BigBirdForCausalLM',\n",
       " 'BigBirdForMaskedLM',\n",
       " 'BigBirdForMultipleChoice',\n",
       " 'BigBirdForPreTraining',\n",
       " 'BigBirdForQuestionAnswering',\n",
       " 'BigBirdForSequenceClassification',\n",
       " 'BigBirdForTokenClassification',\n",
       " 'BigBirdLayer',\n",
       " 'BigBirdModel',\n",
       " 'BigBirdPegasusConfig',\n",
       " 'BigBirdPegasusForCausalLM',\n",
       " 'BigBirdPegasusForConditionalGeneration',\n",
       " 'BigBirdPegasusForQuestionAnswering',\n",
       " 'BigBirdPegasusForSequenceClassification',\n",
       " 'BigBirdPegasusModel',\n",
       " 'BigBirdPegasusPreTrainedModel',\n",
       " 'BigBirdPreTrainedModel',\n",
       " 'BigBirdTokenizer',\n",
       " 'BigBirdTokenizerFast',\n",
       " 'BioGptConfig',\n",
       " 'BioGptForCausalLM',\n",
       " 'BioGptForSequenceClassification',\n",
       " 'BioGptForTokenClassification',\n",
       " 'BioGptModel',\n",
       " 'BioGptPreTrainedModel',\n",
       " 'BioGptTokenizer',\n",
       " 'BitBackbone',\n",
       " 'BitConfig',\n",
       " 'BitForImageClassification',\n",
       " 'BitImageProcessor',\n",
       " 'BitModel',\n",
       " 'BitPreTrainedModel',\n",
       " 'BitsAndBytesConfig',\n",
       " 'BlenderbotConfig',\n",
       " 'BlenderbotForCausalLM',\n",
       " 'BlenderbotForConditionalGeneration',\n",
       " 'BlenderbotModel',\n",
       " 'BlenderbotPreTrainedModel',\n",
       " 'BlenderbotSmallConfig',\n",
       " 'BlenderbotSmallForCausalLM',\n",
       " 'BlenderbotSmallForConditionalGeneration',\n",
       " 'BlenderbotSmallModel',\n",
       " 'BlenderbotSmallPreTrainedModel',\n",
       " 'BlenderbotSmallTokenizer',\n",
       " 'BlenderbotSmallTokenizerFast',\n",
       " 'BlenderbotTokenizer',\n",
       " 'BlenderbotTokenizerFast',\n",
       " 'Blip2Config',\n",
       " 'Blip2ForConditionalGeneration',\n",
       " 'Blip2Model',\n",
       " 'Blip2PreTrainedModel',\n",
       " 'Blip2Processor',\n",
       " 'Blip2QFormerConfig',\n",
       " 'Blip2QFormerModel',\n",
       " 'Blip2VisionConfig',\n",
       " 'Blip2VisionModel',\n",
       " 'BlipConfig',\n",
       " 'BlipForConditionalGeneration',\n",
       " 'BlipForImageTextRetrieval',\n",
       " 'BlipForQuestionAnswering',\n",
       " 'BlipImageProcessor',\n",
       " 'BlipModel',\n",
       " 'BlipPreTrainedModel',\n",
       " 'BlipProcessor',\n",
       " 'BlipTextConfig',\n",
       " 'BlipTextModel',\n",
       " 'BlipVisionConfig',\n",
       " 'BlipVisionModel',\n",
       " 'BloomConfig',\n",
       " 'BloomForCausalLM',\n",
       " 'BloomForQuestionAnswering',\n",
       " 'BloomForSequenceClassification',\n",
       " 'BloomForTokenClassification',\n",
       " 'BloomModel',\n",
       " 'BloomPreTrainedModel',\n",
       " 'BloomTokenizerFast',\n",
       " 'BridgeTowerConfig',\n",
       " 'BridgeTowerForContrastiveLearning',\n",
       " 'BridgeTowerForImageAndTextRetrieval',\n",
       " 'BridgeTowerForMaskedLM',\n",
       " 'BridgeTowerImageProcessor',\n",
       " 'BridgeTowerModel',\n",
       " 'BridgeTowerPreTrainedModel',\n",
       " 'BridgeTowerProcessor',\n",
       " 'BridgeTowerTextConfig',\n",
       " 'BridgeTowerVisionConfig',\n",
       " 'BrosConfig',\n",
       " 'BrosForTokenClassification',\n",
       " 'BrosModel',\n",
       " 'BrosPreTrainedModel',\n",
       " 'BrosProcessor',\n",
       " 'BrosSpadeEEForTokenClassification',\n",
       " 'BrosSpadeELForTokenClassification',\n",
       " 'ByT5Tokenizer',\n",
       " 'CLIPConfig',\n",
       " 'CLIPFeatureExtractor',\n",
       " 'CLIPForImageClassification',\n",
       " 'CLIPImageProcessor',\n",
       " 'CLIPModel',\n",
       " 'CLIPPreTrainedModel',\n",
       " 'CLIPProcessor',\n",
       " 'CLIPSegConfig',\n",
       " 'CLIPSegForImageSegmentation',\n",
       " 'CLIPSegModel',\n",
       " 'CLIPSegPreTrainedModel',\n",
       " 'CLIPSegProcessor',\n",
       " 'CLIPSegTextConfig',\n",
       " 'CLIPSegTextModel',\n",
       " 'CLIPSegVisionConfig',\n",
       " 'CLIPSegVisionModel',\n",
       " 'CLIPTextConfig',\n",
       " 'CLIPTextModel',\n",
       " 'CLIPTextModelWithProjection',\n",
       " 'CLIPTokenizer',\n",
       " 'CLIPTokenizerFast',\n",
       " 'CLIPVisionConfig',\n",
       " 'CLIPVisionModel',\n",
       " 'CLIPVisionModelWithProjection',\n",
       " 'CONFIG_MAPPING',\n",
       " 'CONFIG_NAME',\n",
       " 'CTRLConfig',\n",
       " 'CTRLForSequenceClassification',\n",
       " 'CTRLLMHeadModel',\n",
       " 'CTRLModel',\n",
       " 'CTRLPreTrainedModel',\n",
       " 'CTRLTokenizer',\n",
       " 'Cache',\n",
       " 'CacheConfig',\n",
       " 'CamembertConfig',\n",
       " 'CamembertForCausalLM',\n",
       " 'CamembertForMaskedLM',\n",
       " 'CamembertForMultipleChoice',\n",
       " 'CamembertForQuestionAnswering',\n",
       " 'CamembertForSequenceClassification',\n",
       " 'CamembertForTokenClassification',\n",
       " 'CamembertModel',\n",
       " 'CamembertPreTrainedModel',\n",
       " 'CamembertTokenizer',\n",
       " 'CamembertTokenizerFast',\n",
       " 'CanineConfig',\n",
       " 'CanineForMultipleChoice',\n",
       " 'CanineForQuestionAnswering',\n",
       " 'CanineForSequenceClassification',\n",
       " 'CanineForTokenClassification',\n",
       " 'CanineLayer',\n",
       " 'CanineModel',\n",
       " 'CaninePreTrainedModel',\n",
       " 'CanineTokenizer',\n",
       " 'ChameleonConfig',\n",
       " 'ChameleonForConditionalGeneration',\n",
       " 'ChameleonImageProcessor',\n",
       " 'ChameleonModel',\n",
       " 'ChameleonPreTrainedModel',\n",
       " 'ChameleonProcessor',\n",
       " 'ChameleonVQVAE',\n",
       " 'ChameleonVQVAEConfig',\n",
       " 'CharSpan',\n",
       " 'CharacterTokenizer',\n",
       " 'ChineseCLIPConfig',\n",
       " 'ChineseCLIPFeatureExtractor',\n",
       " 'ChineseCLIPImageProcessor',\n",
       " 'ChineseCLIPModel',\n",
       " 'ChineseCLIPPreTrainedModel',\n",
       " 'ChineseCLIPProcessor',\n",
       " 'ChineseCLIPTextConfig',\n",
       " 'ChineseCLIPTextModel',\n",
       " 'ChineseCLIPVisionConfig',\n",
       " 'ChineseCLIPVisionModel',\n",
       " 'ClapAudioConfig',\n",
       " 'ClapAudioModel',\n",
       " 'ClapAudioModelWithProjection',\n",
       " 'ClapConfig',\n",
       " 'ClapFeatureExtractor',\n",
       " 'ClapModel',\n",
       " 'ClapPreTrainedModel',\n",
       " 'ClapProcessor',\n",
       " 'ClapTextConfig',\n",
       " 'ClapTextModel',\n",
       " 'ClapTextModelWithProjection',\n",
       " 'ClassifierFreeGuidanceLogitsProcessor',\n",
       " 'ClvpConfig',\n",
       " 'ClvpDecoder',\n",
       " 'ClvpDecoderConfig',\n",
       " 'ClvpEncoder',\n",
       " 'ClvpEncoderConfig',\n",
       " 'ClvpFeatureExtractor',\n",
       " 'ClvpForCausalLM',\n",
       " 'ClvpModel',\n",
       " 'ClvpModelForConditionalGeneration',\n",
       " 'ClvpPreTrainedModel',\n",
       " 'ClvpProcessor',\n",
       " 'ClvpTokenizer',\n",
       " 'CodeAgent',\n",
       " 'CodeGenConfig',\n",
       " 'CodeGenForCausalLM',\n",
       " 'CodeGenModel',\n",
       " 'CodeGenPreTrainedModel',\n",
       " 'CodeGenTokenizer',\n",
       " 'CodeGenTokenizerFast',\n",
       " 'CodeLlamaTokenizer',\n",
       " 'CodeLlamaTokenizerFast',\n",
       " 'CohereConfig',\n",
       " 'CohereForCausalLM',\n",
       " 'CohereModel',\n",
       " 'CoherePreTrainedModel',\n",
       " 'CohereTokenizerFast',\n",
       " 'ConditionalDetrConfig',\n",
       " 'ConditionalDetrFeatureExtractor',\n",
       " 'ConditionalDetrForObjectDetection',\n",
       " 'ConditionalDetrForSegmentation',\n",
       " 'ConditionalDetrImageProcessor',\n",
       " 'ConditionalDetrModel',\n",
       " 'ConditionalDetrPreTrainedModel',\n",
       " 'ConstrainedBeamSearchScorer',\n",
       " 'Constraint',\n",
       " 'ConstraintListState',\n",
       " 'Conv1D',\n",
       " 'ConvBertConfig',\n",
       " 'ConvBertForMaskedLM',\n",
       " 'ConvBertForMultipleChoice',\n",
       " 'ConvBertForQuestionAnswering',\n",
       " 'ConvBertForSequenceClassification',\n",
       " 'ConvBertForTokenClassification',\n",
       " 'ConvBertLayer',\n",
       " 'ConvBertModel',\n",
       " 'ConvBertPreTrainedModel',\n",
       " 'ConvBertTokenizer',\n",
       " 'ConvBertTokenizerFast',\n",
       " 'ConvNextBackbone',\n",
       " 'ConvNextConfig',\n",
       " 'ConvNextFeatureExtractor',\n",
       " 'ConvNextForImageClassification',\n",
       " 'ConvNextImageProcessor',\n",
       " 'ConvNextModel',\n",
       " 'ConvNextPreTrainedModel',\n",
       " 'ConvNextV2Backbone',\n",
       " 'ConvNextV2Config',\n",
       " 'ConvNextV2ForImageClassification',\n",
       " 'ConvNextV2Model',\n",
       " 'ConvNextV2PreTrainedModel',\n",
       " 'CpmAntConfig',\n",
       " 'CpmAntForCausalLM',\n",
       " 'CpmAntModel',\n",
       " 'CpmAntPreTrainedModel',\n",
       " 'CpmAntTokenizer',\n",
       " 'CpmTokenizer',\n",
       " 'CpmTokenizerFast',\n",
       " 'CsvPipelineDataFormat',\n",
       " 'CvtConfig',\n",
       " 'CvtForImageClassification',\n",
       " 'CvtModel',\n",
       " 'CvtPreTrainedModel',\n",
       " 'DPRConfig',\n",
       " 'DPRContextEncoder',\n",
       " 'DPRContextEncoderTokenizer',\n",
       " 'DPRContextEncoderTokenizerFast',\n",
       " 'DPRPreTrainedModel',\n",
       " 'DPRPretrainedContextEncoder',\n",
       " 'DPRPretrainedQuestionEncoder',\n",
       " 'DPRPretrainedReader',\n",
       " 'DPRQuestionEncoder',\n",
       " 'DPRQuestionEncoderTokenizer',\n",
       " 'DPRQuestionEncoderTokenizerFast',\n",
       " 'DPRReader',\n",
       " 'DPRReaderOutput',\n",
       " 'DPRReaderTokenizer',\n",
       " 'DPRReaderTokenizerFast',\n",
       " 'DPTConfig',\n",
       " 'DPTFeatureExtractor',\n",
       " 'DPTForDepthEstimation',\n",
       " 'DPTForSemanticSegmentation',\n",
       " 'DPTImageProcessor',\n",
       " 'DPTModel',\n",
       " 'DPTPreTrainedModel',\n",
       " 'Data2VecAudioConfig',\n",
       " 'Data2VecAudioForAudioFrameClassification',\n",
       " 'Data2VecAudioForCTC',\n",
       " 'Data2VecAudioForSequenceClassification',\n",
       " 'Data2VecAudioForXVector',\n",
       " 'Data2VecAudioModel',\n",
       " 'Data2VecAudioPreTrainedModel',\n",
       " 'Data2VecTextConfig',\n",
       " 'Data2VecTextForCausalLM',\n",
       " 'Data2VecTextForMaskedLM',\n",
       " 'Data2VecTextForMultipleChoice',\n",
       " 'Data2VecTextForQuestionAnswering',\n",
       " 'Data2VecTextForSequenceClassification',\n",
       " 'Data2VecTextForTokenClassification',\n",
       " 'Data2VecTextModel',\n",
       " 'Data2VecTextPreTrainedModel',\n",
       " 'Data2VecVisionConfig',\n",
       " 'Data2VecVisionForImageClassification',\n",
       " 'Data2VecVisionForSemanticSegmentation',\n",
       " 'Data2VecVisionModel',\n",
       " 'Data2VecVisionPreTrainedModel',\n",
       " 'DataCollator',\n",
       " 'DataCollatorForLanguageModeling',\n",
       " 'DataCollatorForPermutationLanguageModeling',\n",
       " 'DataCollatorForSOP',\n",
       " 'DataCollatorForSeq2Seq',\n",
       " 'DataCollatorForTokenClassification',\n",
       " 'DataCollatorForWholeWordMask',\n",
       " 'DataCollatorWithFlattening',\n",
       " 'DataCollatorWithPadding',\n",
       " 'DataProcessor',\n",
       " 'DbrxConfig',\n",
       " 'DbrxForCausalLM',\n",
       " 'DbrxModel',\n",
       " 'DbrxPreTrainedModel',\n",
       " 'DebertaConfig',\n",
       " 'DebertaForMaskedLM',\n",
       " 'DebertaForQuestionAnswering',\n",
       " 'DebertaForSequenceClassification',\n",
       " 'DebertaForTokenClassification',\n",
       " 'DebertaModel',\n",
       " 'DebertaPreTrainedModel',\n",
       " 'DebertaTokenizer',\n",
       " 'DebertaTokenizerFast',\n",
       " 'DebertaV2Config',\n",
       " 'DebertaV2ForMaskedLM',\n",
       " 'DebertaV2ForMultipleChoice',\n",
       " 'DebertaV2ForQuestionAnswering',\n",
       " 'DebertaV2ForSequenceClassification',\n",
       " 'DebertaV2ForTokenClassification',\n",
       " 'DebertaV2Model',\n",
       " 'DebertaV2PreTrainedModel',\n",
       " 'DebertaV2Tokenizer',\n",
       " 'DebertaV2TokenizerFast',\n",
       " 'DecisionTransformerConfig',\n",
       " 'DecisionTransformerGPT2Model',\n",
       " 'DecisionTransformerGPT2PreTrainedModel',\n",
       " 'DecisionTransformerModel',\n",
       " 'DecisionTransformerPreTrainedModel',\n",
       " 'DefaultDataCollator',\n",
       " 'DefaultFlowCallback',\n",
       " 'DeformableDetrConfig',\n",
       " 'DeformableDetrFeatureExtractor',\n",
       " 'DeformableDetrForObjectDetection',\n",
       " 'DeformableDetrImageProcessor',\n",
       " 'DeformableDetrModel',\n",
       " 'DeformableDetrPreTrainedModel',\n",
       " 'DeiTConfig',\n",
       " 'DeiTFeatureExtractor',\n",
       " 'DeiTForImageClassification',\n",
       " 'DeiTForImageClassificationWithTeacher',\n",
       " 'DeiTForMaskedImageModeling',\n",
       " 'DeiTImageProcessor',\n",
       " 'DeiTModel',\n",
       " 'DeiTPreTrainedModel',\n",
       " 'DepthAnythingConfig',\n",
       " 'DepthAnythingForDepthEstimation',\n",
       " 'DepthAnythingPreTrainedModel',\n",
       " 'DepthEstimationPipeline',\n",
       " 'DetaConfig',\n",
       " 'DetaForObjectDetection',\n",
       " 'DetaImageProcessor',\n",
       " 'DetaModel',\n",
       " 'DetaPreTrainedModel',\n",
       " 'DetrConfig',\n",
       " 'DetrFeatureExtractor',\n",
       " 'DetrForObjectDetection',\n",
       " 'DetrForSegmentation',\n",
       " 'DetrImageProcessor',\n",
       " 'DetrModel',\n",
       " 'DetrPreTrainedModel',\n",
       " 'DinatBackbone',\n",
       " 'DinatConfig',\n",
       " 'DinatForImageClassification',\n",
       " 'DinatModel',\n",
       " 'DinatPreTrainedModel',\n",
       " 'Dinov2Backbone',\n",
       " 'Dinov2Config',\n",
       " 'Dinov2ForImageClassification',\n",
       " 'Dinov2Model',\n",
       " 'Dinov2PreTrainedModel',\n",
       " 'DisjunctiveConstraint',\n",
       " 'DistilBertConfig',\n",
       " 'DistilBertForMaskedLM',\n",
       " 'DistilBertForMultipleChoice',\n",
       " 'DistilBertForQuestionAnswering',\n",
       " 'DistilBertForSequenceClassification',\n",
       " 'DistilBertForTokenClassification',\n",
       " 'DistilBertModel',\n",
       " 'DistilBertPreTrainedModel',\n",
       " 'DistilBertTokenizer',\n",
       " 'DistilBertTokenizerFast',\n",
       " 'DocumentQuestionAnsweringPipeline',\n",
       " 'DonutFeatureExtractor',\n",
       " 'DonutImageProcessor',\n",
       " 'DonutProcessor',\n",
       " 'DonutSwinConfig',\n",
       " 'DonutSwinModel',\n",
       " 'DonutSwinPreTrainedModel',\n",
       " 'DummyObject',\n",
       " 'DynamicCache',\n",
       " 'EarlyStoppingCallback',\n",
       " 'EetqConfig',\n",
       " 'EfficientFormerConfig',\n",
       " 'EfficientFormerForImageClassification',\n",
       " 'EfficientFormerForImageClassificationWithTeacher',\n",
       " 'EfficientFormerImageProcessor',\n",
       " 'EfficientFormerModel',\n",
       " 'EfficientFormerPreTrainedModel',\n",
       " 'EfficientNetConfig',\n",
       " 'EfficientNetForImageClassification',\n",
       " 'EfficientNetImageProcessor',\n",
       " 'EfficientNetModel',\n",
       " 'EfficientNetPreTrainedModel',\n",
       " 'ElectraConfig',\n",
       " 'ElectraForCausalLM',\n",
       " 'ElectraForMaskedLM',\n",
       " 'ElectraForMultipleChoice',\n",
       " 'ElectraForPreTraining',\n",
       " 'ElectraForQuestionAnswering',\n",
       " 'ElectraForSequenceClassification',\n",
       " 'ElectraForTokenClassification',\n",
       " 'ElectraModel',\n",
       " 'ElectraPreTrainedModel',\n",
       " 'ElectraTokenizer',\n",
       " 'ElectraTokenizerFast',\n",
       " 'EncodecConfig',\n",
       " 'EncodecFeatureExtractor',\n",
       " 'EncodecModel',\n",
       " 'EncodecPreTrainedModel',\n",
       " 'EncoderDecoderCache',\n",
       " 'EncoderDecoderConfig',\n",
       " 'EncoderDecoderModel',\n",
       " 'EncoderNoRepeatNGramLogitsProcessor',\n",
       " 'EncoderRepetitionPenaltyLogitsProcessor',\n",
       " 'EosTokenCriteria',\n",
       " 'EpsilonLogitsWarper',\n",
       " 'ErnieConfig',\n",
       " 'ErnieForCausalLM',\n",
       " 'ErnieForMaskedLM',\n",
       " 'ErnieForMultipleChoice',\n",
       " 'ErnieForNextSentencePrediction',\n",
       " 'ErnieForPreTraining',\n",
       " 'ErnieForQuestionAnswering',\n",
       " 'ErnieForSequenceClassification',\n",
       " 'ErnieForTokenClassification',\n",
       " 'ErnieMConfig',\n",
       " 'ErnieMForInformationExtraction',\n",
       " 'ErnieMForMultipleChoice',\n",
       " 'ErnieMForQuestionAnswering',\n",
       " 'ErnieMForSequenceClassification',\n",
       " 'ErnieMForTokenClassification',\n",
       " 'ErnieMModel',\n",
       " 'ErnieMPreTrainedModel',\n",
       " 'ErnieMTokenizer',\n",
       " 'ErnieModel',\n",
       " 'ErniePreTrainedModel',\n",
       " 'EsmConfig',\n",
       " 'EsmFoldPreTrainedModel',\n",
       " 'EsmForMaskedLM',\n",
       " 'EsmForProteinFolding',\n",
       " 'EsmForSequenceClassification',\n",
       " 'EsmForTokenClassification',\n",
       " 'EsmModel',\n",
       " 'EsmPreTrainedModel',\n",
       " 'EsmTokenizer',\n",
       " 'EtaLogitsWarper',\n",
       " 'EvalPrediction',\n",
       " 'ExponentialDecayLengthPenalty',\n",
       " 'FEATURE_EXTRACTOR_MAPPING',\n",
       " 'FLAX_MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING',\n",
       " 'FLAX_MODEL_FOR_CAUSAL_LM_MAPPING',\n",
       " 'FLAX_MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING',\n",
       " 'FLAX_MODEL_FOR_MASKED_LM_MAPPING',\n",
       " 'FLAX_MODEL_FOR_MULTIPLE_CHOICE_MAPPING',\n",
       " 'FLAX_MODEL_FOR_NEXT_SENTENCE_PREDICTION_MAPPING',\n",
       " 'FLAX_MODEL_FOR_PRETRAINING_MAPPING',\n",
       " 'FLAX_MODEL_FOR_QUESTION_ANSWERING_MAPPING',\n",
       " 'FLAX_MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING',\n",
       " 'FLAX_MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING',\n",
       " 'FLAX_MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING',\n",
       " 'FLAX_MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING',\n",
       " 'FLAX_MODEL_FOR_VISION_2_SEQ_MAPPING',\n",
       " 'FLAX_MODEL_MAPPING',\n",
       " 'FNetConfig',\n",
       " 'FNetForMaskedLM',\n",
       " 'FNetForMultipleChoice',\n",
       " 'FNetForNextSentencePrediction',\n",
       " 'FNetForPreTraining',\n",
       " 'FNetForQuestionAnswering',\n",
       " 'FNetForSequenceClassification',\n",
       " 'FNetForTokenClassification',\n",
       " 'FNetLayer',\n",
       " 'FNetModel',\n",
       " 'FNetPreTrainedModel',\n",
       " 'FNetTokenizer',\n",
       " 'FNetTokenizerFast',\n",
       " 'FSMTConfig',\n",
       " 'FSMTForConditionalGeneration',\n",
       " 'FSMTModel',\n",
       " 'FSMTTokenizer',\n",
       " 'FalconConfig',\n",
       " 'FalconForCausalLM',\n",
       " 'FalconForQuestionAnswering',\n",
       " 'FalconForSequenceClassification',\n",
       " 'FalconForTokenClassification',\n",
       " 'FalconModel',\n",
       " 'FalconPreTrainedModel',\n",
       " 'FastSpeech2ConformerConfig',\n",
       " 'FastSpeech2ConformerHifiGan',\n",
       " 'FastSpeech2ConformerHifiGanConfig',\n",
       " 'FastSpeech2ConformerModel',\n",
       " 'FastSpeech2ConformerPreTrainedModel',\n",
       " 'FastSpeech2ConformerTokenizer',\n",
       " 'FastSpeech2ConformerWithHifiGan',\n",
       " 'FastSpeech2ConformerWithHifiGanConfig',\n",
       " 'FbgemmFp8Config',\n",
       " 'FeatureExtractionMixin',\n",
       " 'FeatureExtractionPipeline',\n",
       " 'FillMaskPipeline',\n",
       " 'FlaubertConfig',\n",
       " 'FlaubertForMultipleChoice',\n",
       " 'FlaubertForQuestionAnswering',\n",
       " 'FlaubertForQuestionAnsweringSimple',\n",
       " 'FlaubertForSequenceClassification',\n",
       " 'FlaubertForTokenClassification',\n",
       " 'FlaubertModel',\n",
       " 'FlaubertPreTrainedModel',\n",
       " 'FlaubertTokenizer',\n",
       " 'FlaubertWithLMHeadModel',\n",
       " 'FlavaConfig',\n",
       " 'FlavaFeatureExtractor',\n",
       " 'FlavaForPreTraining',\n",
       " 'FlavaImageCodebook',\n",
       " 'FlavaImageCodebookConfig',\n",
       " 'FlavaImageConfig',\n",
       " 'FlavaImageModel',\n",
       " 'FlavaImageProcessor',\n",
       " 'FlavaModel',\n",
       " 'FlavaMultimodalConfig',\n",
       " 'FlavaMultimodalModel',\n",
       " 'FlavaPreTrainedModel',\n",
       " 'FlavaProcessor',\n",
       " 'FlavaTextConfig',\n",
       " 'FlavaTextModel',\n",
       " 'FlaxAlbertForMaskedLM',\n",
       " 'FlaxAlbertForMultipleChoice',\n",
       " 'FlaxAlbertForPreTraining',\n",
       " 'FlaxAlbertForQuestionAnswering',\n",
       " 'FlaxAlbertForSequenceClassification',\n",
       " 'FlaxAlbertForTokenClassification',\n",
       " 'FlaxAlbertModel',\n",
       " 'FlaxAlbertPreTrainedModel',\n",
       " 'FlaxAutoModel',\n",
       " 'FlaxAutoModelForCausalLM',\n",
       " 'FlaxAutoModelForImageClassification',\n",
       " 'FlaxAutoModelForMaskedLM',\n",
       " 'FlaxAutoModelForMultipleChoice',\n",
       " 'FlaxAutoModelForNextSentencePrediction',\n",
       " 'FlaxAutoModelForPreTraining',\n",
       " 'FlaxAutoModelForQuestionAnswering',\n",
       " 'FlaxAutoModelForSeq2SeqLM',\n",
       " 'FlaxAutoModelForSequenceClassification',\n",
       " 'FlaxAutoModelForSpeechSeq2Seq',\n",
       " 'FlaxAutoModelForTokenClassification',\n",
       " 'FlaxAutoModelForVision2Seq',\n",
       " 'FlaxBartDecoderPreTrainedModel',\n",
       " 'FlaxBartForCausalLM',\n",
       " 'FlaxBartForConditionalGeneration',\n",
       " 'FlaxBartForQuestionAnswering',\n",
       " 'FlaxBartForSequenceClassification',\n",
       " 'FlaxBartModel',\n",
       " 'FlaxBartPreTrainedModel',\n",
       " 'FlaxBeitForImageClassification',\n",
       " 'FlaxBeitForMaskedImageModeling',\n",
       " 'FlaxBeitModel',\n",
       " 'FlaxBeitPreTrainedModel',\n",
       " 'FlaxBertForCausalLM',\n",
       " 'FlaxBertForMaskedLM',\n",
       " 'FlaxBertForMultipleChoice',\n",
       " 'FlaxBertForNextSentencePrediction',\n",
       " 'FlaxBertForPreTraining',\n",
       " 'FlaxBertForQuestionAnswering',\n",
       " 'FlaxBertForSequenceClassification',\n",
       " 'FlaxBertForTokenClassification',\n",
       " 'FlaxBertModel',\n",
       " 'FlaxBertPreTrainedModel',\n",
       " 'FlaxBigBirdForCausalLM',\n",
       " 'FlaxBigBirdForMaskedLM',\n",
       " 'FlaxBigBirdForMultipleChoice',\n",
       " 'FlaxBigBirdForPreTraining',\n",
       " 'FlaxBigBirdForQuestionAnswering',\n",
       " 'FlaxBigBirdForSequenceClassification',\n",
       " 'FlaxBigBirdForTokenClassification',\n",
       " 'FlaxBigBirdModel',\n",
       " 'FlaxBigBirdPreTrainedModel',\n",
       " 'FlaxBlenderbotForConditionalGeneration',\n",
       " 'FlaxBlenderbotModel',\n",
       " 'FlaxBlenderbotPreTrainedModel',\n",
       " 'FlaxBlenderbotSmallForConditionalGeneration',\n",
       " 'FlaxBlenderbotSmallModel',\n",
       " 'FlaxBlenderbotSmallPreTrainedModel',\n",
       " 'FlaxBloomForCausalLM',\n",
       " 'FlaxBloomModel',\n",
       " 'FlaxBloomPreTrainedModel',\n",
       " 'FlaxCLIPModel',\n",
       " 'FlaxCLIPPreTrainedModel',\n",
       " 'FlaxCLIPTextModel',\n",
       " 'FlaxCLIPTextModelWithProjection',\n",
       " 'FlaxCLIPTextPreTrainedModel',\n",
       " 'FlaxCLIPVisionModel',\n",
       " 'FlaxCLIPVisionPreTrainedModel',\n",
       " 'FlaxDistilBertForMaskedLM',\n",
       " 'FlaxDistilBertForMultipleChoice',\n",
       " 'FlaxDistilBertForQuestionAnswering',\n",
       " 'FlaxDistilBertForSequenceClassification',\n",
       " 'FlaxDistilBertForTokenClassification',\n",
       " 'FlaxDistilBertModel',\n",
       " 'FlaxDistilBertPreTrainedModel',\n",
       " 'FlaxElectraForCausalLM',\n",
       " 'FlaxElectraForMaskedLM',\n",
       " 'FlaxElectraForMultipleChoice',\n",
       " 'FlaxElectraForPreTraining',\n",
       " 'FlaxElectraForQuestionAnswering',\n",
       " 'FlaxElectraForSequenceClassification',\n",
       " 'FlaxElectraForTokenClassification',\n",
       " 'FlaxElectraModel',\n",
       " 'FlaxElectraPreTrainedModel',\n",
       " 'FlaxEncoderDecoderModel',\n",
       " 'FlaxForceTokensLogitsProcessor',\n",
       " 'FlaxForcedBOSTokenLogitsProcessor',\n",
       " 'FlaxForcedEOSTokenLogitsProcessor',\n",
       " 'FlaxGPT2LMHeadModel',\n",
       " 'FlaxGPT2Model',\n",
       " 'FlaxGPT2PreTrainedModel',\n",
       " 'FlaxGPTJForCausalLM',\n",
       " 'FlaxGPTJModel',\n",
       " 'FlaxGPTJPreTrainedModel',\n",
       " 'FlaxGPTNeoForCausalLM',\n",
       " 'FlaxGPTNeoModel',\n",
       " 'FlaxGPTNeoPreTrainedModel',\n",
       " 'FlaxGemmaForCausalLM',\n",
       " 'FlaxGemmaModel',\n",
       " 'FlaxGemmaPreTrainedModel',\n",
       " 'FlaxGenerationMixin',\n",
       " 'FlaxLlamaForCausalLM',\n",
       " 'FlaxLlamaModel',\n",
       " 'FlaxLlamaPreTrainedModel',\n",
       " 'FlaxLogitsProcessor',\n",
       " 'FlaxLogitsProcessorList',\n",
       " 'FlaxLogitsWarper',\n",
       " 'FlaxLongT5ForConditionalGeneration',\n",
       " 'FlaxLongT5Model',\n",
       " 'FlaxLongT5PreTrainedModel',\n",
       " 'FlaxMBartForConditionalGeneration',\n",
       " 'FlaxMBartForQuestionAnswering',\n",
       " 'FlaxMBartForSequenceClassification',\n",
       " 'FlaxMBartModel',\n",
       " 'FlaxMBartPreTrainedModel',\n",
       " 'FlaxMT5EncoderModel',\n",
       " 'FlaxMT5ForConditionalGeneration',\n",
       " 'FlaxMT5Model',\n",
       " 'FlaxMarianMTModel',\n",
       " 'FlaxMarianModel',\n",
       " 'FlaxMarianPreTrainedModel',\n",
       " 'FlaxMinLengthLogitsProcessor',\n",
       " 'FlaxMistralForCausalLM',\n",
       " 'FlaxMistralModel',\n",
       " 'FlaxMistralPreTrainedModel',\n",
       " 'FlaxOPTForCausalLM',\n",
       " 'FlaxOPTModel',\n",
       " 'FlaxOPTPreTrainedModel',\n",
       " 'FlaxPegasusForConditionalGeneration',\n",
       " 'FlaxPegasusModel',\n",
       " 'FlaxPegasusPreTrainedModel',\n",
       " 'FlaxPreTrainedModel',\n",
       " 'FlaxRegNetForImageClassification',\n",
       " 'FlaxRegNetModel',\n",
       " 'FlaxRegNetPreTrainedModel',\n",
       " 'FlaxResNetForImageClassification',\n",
       " 'FlaxResNetModel',\n",
       " 'FlaxResNetPreTrainedModel',\n",
       " 'FlaxRoFormerForMaskedLM',\n",
       " 'FlaxRoFormerForMultipleChoice',\n",
       " 'FlaxRoFormerForQuestionAnswering',\n",
       " 'FlaxRoFormerForSequenceClassification',\n",
       " 'FlaxRoFormerForTokenClassification',\n",
       " 'FlaxRoFormerModel',\n",
       " 'FlaxRoFormerPreTrainedModel',\n",
       " 'FlaxRobertaForCausalLM',\n",
       " 'FlaxRobertaForMaskedLM',\n",
       " 'FlaxRobertaForMultipleChoice',\n",
       " 'FlaxRobertaForQuestionAnswering',\n",
       " 'FlaxRobertaForSequenceClassification',\n",
       " 'FlaxRobertaForTokenClassification',\n",
       " 'FlaxRobertaModel',\n",
       " 'FlaxRobertaPreLayerNormForCausalLM',\n",
       " 'FlaxRobertaPreLayerNormForMaskedLM',\n",
       " 'FlaxRobertaPreLayerNormForMultipleChoice',\n",
       " 'FlaxRobertaPreLayerNormForQuestionAnswering',\n",
       " 'FlaxRobertaPreLayerNormForSequenceClassification',\n",
       " 'FlaxRobertaPreLayerNormForTokenClassification',\n",
       " 'FlaxRobertaPreLayerNormModel',\n",
       " 'FlaxRobertaPreLayerNormPreTrainedModel',\n",
       " 'FlaxRobertaPreTrainedModel',\n",
       " 'FlaxSpeechEncoderDecoderModel',\n",
       " 'FlaxSuppressTokensAtBeginLogitsProcessor',\n",
       " 'FlaxSuppressTokensLogitsProcessor',\n",
       " 'FlaxT5EncoderModel',\n",
       " 'FlaxT5ForConditionalGeneration',\n",
       " 'FlaxT5Model',\n",
       " 'FlaxT5PreTrainedModel',\n",
       " 'FlaxTemperatureLogitsWarper',\n",
       " 'FlaxTopKLogitsWarper',\n",
       " 'FlaxTopPLogitsWarper',\n",
       " 'FlaxViTForImageClassification',\n",
       " 'FlaxViTModel',\n",
       " 'FlaxViTPreTrainedModel',\n",
       " 'FlaxVisionEncoderDecoderModel',\n",
       " 'FlaxVisionTextDualEncoderModel',\n",
       " 'FlaxWav2Vec2ForCTC',\n",
       " 'FlaxWav2Vec2ForPreTraining',\n",
       " 'FlaxWav2Vec2Model',\n",
       " 'FlaxWav2Vec2PreTrainedModel',\n",
       " 'FlaxWhisperForAudioClassification',\n",
       " 'FlaxWhisperForConditionalGeneration',\n",
       " 'FlaxWhisperModel',\n",
       " 'FlaxWhisperPreTrainedModel',\n",
       " 'FlaxWhisperTimeStampLogitsProcessor',\n",
       " 'FlaxXGLMForCausalLM',\n",
       " 'FlaxXGLMModel',\n",
       " 'FlaxXGLMPreTrainedModel',\n",
       " 'FlaxXLMRobertaForCausalLM',\n",
       " 'FlaxXLMRobertaForMaskedLM',\n",
       " 'FlaxXLMRobertaForMultipleChoice',\n",
       " 'FlaxXLMRobertaForQuestionAnswering',\n",
       " 'FlaxXLMRobertaForSequenceClassification',\n",
       " 'FlaxXLMRobertaForTokenClassification',\n",
       " 'FlaxXLMRobertaModel',\n",
       " 'FlaxXLMRobertaPreTrainedModel',\n",
       " 'FocalNetBackbone',\n",
       " 'FocalNetConfig',\n",
       " 'FocalNetForImageClassification',\n",
       " 'FocalNetForMaskedImageModeling',\n",
       " 'FocalNetModel',\n",
       " 'FocalNetPreTrainedModel',\n",
       " 'ForceTokensLogitsProcessor',\n",
       " 'ForcedBOSTokenLogitsProcessor',\n",
       " 'ForcedEOSTokenLogitsProcessor',\n",
       " 'FunnelBaseModel',\n",
       " 'FunnelConfig',\n",
       " 'FunnelForMaskedLM',\n",
       " 'FunnelForMultipleChoice',\n",
       " 'FunnelForPreTraining',\n",
       " 'FunnelForQuestionAnswering',\n",
       " 'FunnelForSequenceClassification',\n",
       " 'FunnelForTokenClassification',\n",
       " 'FunnelModel',\n",
       " 'FunnelPreTrainedModel',\n",
       " 'FunnelTokenizer',\n",
       " 'FunnelTokenizerFast',\n",
       " 'FuyuConfig',\n",
       " 'FuyuForCausalLM',\n",
       " 'FuyuImageProcessor',\n",
       " 'FuyuPreTrainedModel',\n",
       " 'FuyuProcessor',\n",
       " 'GLPNConfig',\n",
       " 'GLPNFeatureExtractor',\n",
       " 'GLPNForDepthEstimation',\n",
       " 'GLPNImageProcessor',\n",
       " 'GLPNModel',\n",
       " 'GLPNPreTrainedModel',\n",
       " 'GPT2Config',\n",
       " 'GPT2DoubleHeadsModel',\n",
       " 'GPT2ForQuestionAnswering',\n",
       " 'GPT2ForSequenceClassification',\n",
       " 'GPT2ForTokenClassification',\n",
       " 'GPT2LMHeadModel',\n",
       " 'GPT2Model',\n",
       " 'GPT2PreTrainedModel',\n",
       " 'GPT2Tokenizer',\n",
       " 'GPT2TokenizerFast',\n",
       " 'GPTBigCodeConfig',\n",
       " 'GPTBigCodeForCausalLM',\n",
       " 'GPTBigCodeForSequenceClassification',\n",
       " 'GPTBigCodeForTokenClassification',\n",
       " 'GPTBigCodeModel',\n",
       " 'GPTBigCodePreTrainedModel',\n",
       " 'GPTJConfig',\n",
       " 'GPTJForCausalLM',\n",
       " 'GPTJForQuestionAnswering',\n",
       " 'GPTJForSequenceClassification',\n",
       " 'GPTJModel',\n",
       " 'GPTJPreTrainedModel',\n",
       " 'GPTNeoConfig',\n",
       " 'GPTNeoForCausalLM',\n",
       " 'GPTNeoForQuestionAnswering',\n",
       " 'GPTNeoForSequenceClassification',\n",
       " 'GPTNeoForTokenClassification',\n",
       " 'GPTNeoModel',\n",
       " 'GPTNeoPreTrainedModel',\n",
       " 'GPTNeoXConfig',\n",
       " 'GPTNeoXForCausalLM',\n",
       " 'GPTNeoXForQuestionAnswering',\n",
       " 'GPTNeoXForSequenceClassification',\n",
       " 'GPTNeoXForTokenClassification',\n",
       " 'GPTNeoXJapaneseConfig',\n",
       " 'GPTNeoXJapaneseForCausalLM',\n",
       " 'GPTNeoXJapaneseLayer',\n",
       " 'GPTNeoXJapaneseModel',\n",
       " 'GPTNeoXJapanesePreTrainedModel',\n",
       " 'GPTNeoXJapaneseTokenizer',\n",
       " 'GPTNeoXLayer',\n",
       " 'GPTNeoXModel',\n",
       " 'GPTNeoXPreTrainedModel',\n",
       " 'GPTNeoXTokenizerFast',\n",
       " 'GPTQConfig',\n",
       " 'GPTSanJapaneseConfig',\n",
       " 'GPTSanJapaneseForConditionalGeneration',\n",
       " 'GPTSanJapaneseModel',\n",
       " 'GPTSanJapanesePreTrainedModel',\n",
       " 'GPTSanJapaneseTokenizer',\n",
       " 'GPTSw3Tokenizer',\n",
       " 'Gemma2Config',\n",
       " 'Gemma2ForCausalLM',\n",
       " 'Gemma2ForSequenceClassification',\n",
       " 'Gemma2ForTokenClassification',\n",
       " 'Gemma2Model',\n",
       " 'Gemma2PreTrainedModel',\n",
       " 'GemmaConfig',\n",
       " 'GemmaForCausalLM',\n",
       " 'GemmaForSequenceClassification',\n",
       " 'GemmaForTokenClassification',\n",
       " 'GemmaModel',\n",
       " 'GemmaPreTrainedModel',\n",
       " 'GemmaTokenizer',\n",
       " 'GemmaTokenizerFast',\n",
       " 'GenerationConfig',\n",
       " 'GenerationMixin',\n",
       " 'GitConfig',\n",
       " 'GitForCausalLM',\n",
       " 'GitModel',\n",
       " 'GitPreTrainedModel',\n",
       " 'GitProcessor',\n",
       " 'GitVisionConfig',\n",
       " 'GitVisionModel',\n",
       " 'GlueDataTrainingArguments',\n",
       " 'GlueDataset',\n",
       " 'GradientAccumulator',\n",
       " 'GraphormerConfig',\n",
       " 'GraphormerForGraphClassification',\n",
       " 'GraphormerModel',\n",
       " 'GraphormerPreTrainedModel',\n",
       " 'GroundingDinoConfig',\n",
       " ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T12:53:41.681915Z",
     "start_time": "2024-09-14T12:53:41.259590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import CLIPTokenizer, CLIPModel, CLIPProcessor\n",
    "\n",
    "# 示例文本和图像\n",
    "texts = [\"a photo of a cat\", \"a photo of a dog\"]\n",
    "image_path = \"SCR-20240914-scuf.png\"\n",
    "\n",
    "# 加载预训练的CLIP模型和分词器\n",
    "tokenizer = CLIPTokenizer.from_pretrained(\"../.pretrained_models/clip-vit-base-patch32\")\n",
    "model = CLIPModel.from_pretrained(\"../.pretrained_models/clip-vit-base-patch32\")\n",
    "\n",
    "# 加载图像\n",
    "processor = CLIPProcessor.from_pretrained(\"../.pretrained_models/clip-vit-base-patch32\")\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# 处理文本和图像\n",
    "inputs = processor(text=texts, images=image, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "# 获取模型输出\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# 提取文本和图像的嵌入表示\n",
    "text_embeddings = outputs.text_embeds\n",
    "image_embeddings = outputs.image_embeds\n",
    "\n",
    "# 计算相似度\n",
    "cosine_similarities = torch.nn.CosineSimilarity(dim=-1)(text_embeddings, image_embeddings)\n",
    "\n",
    "# 打印相似度\n",
    "print(\"Cosine Similarities:\")\n",
    "print(cosine_similarities)\n",
    "\n",
    "# 打印文本和图像的嵌入表示\n",
    "print(\"Text Embeddings:\")\n",
    "print(text_embeddings)\n",
    "print(\"Image Embeddings:\")\n",
    "print(image_embeddings)\n"
   ],
   "id": "24e0b01882726ebe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarities:\n",
      "tensor([0.2331, 0.1988])\n",
      "Text Embeddings:\n",
      "tensor([[ 0.0148,  0.0070, -0.0234,  ..., -0.0508, -0.0438,  0.0033],\n",
      "        [ 0.0087,  0.0258, -0.0387,  ..., -0.0547, -0.0242,  0.0112]])\n",
      "Image Embeddings:\n",
      "tensor([[-3.1646e-02, -4.4683e-02, -5.3537e-02, -4.1083e-02,  3.5067e-02,\n",
      "         -2.9017e-02, -6.0700e-03,  1.1640e-02,  1.1509e-02, -9.0606e-03,\n",
      "          5.8737e-02, -3.6815e-02,  1.6985e-02, -1.1781e-02, -2.3312e-03,\n",
      "          1.3155e-02, -9.9854e-03, -6.1771e-03,  1.5439e-02,  2.9156e-02,\n",
      "          2.3821e-02,  3.6498e-02,  4.3254e-02, -9.0280e-03, -9.9071e-03,\n",
      "          6.5401e-03, -6.7367e-03, -3.3519e-02, -1.4676e-02, -1.4133e-02,\n",
      "          5.9268e-03,  5.9447e-03,  3.1212e-03,  2.6177e-02,  3.6211e-02,\n",
      "         -1.3909e-02,  3.3059e-02, -1.4424e-02,  7.4597e-03, -1.5723e-01,\n",
      "          1.8544e-02, -8.7091e-03, -1.2254e-02, -5.2413e-02, -9.6742e-03,\n",
      "          7.1011e-02,  2.5645e-02,  1.9217e-02,  1.8643e-02, -4.0501e-02,\n",
      "          2.5664e-02,  5.4755e-02,  8.9778e-04,  7.8116e-03, -9.9959e-03,\n",
      "          2.4980e-02,  2.7686e-02, -2.8005e-03, -6.4597e-03, -7.2337e-03,\n",
      "         -6.8369e-02, -1.2780e-02, -3.1778e-02, -7.7885e-03, -2.2812e-02,\n",
      "         -6.1440e-03, -2.7393e-02, -3.0889e-03, -9.1549e-03,  9.9598e-03,\n",
      "          2.8294e-02, -2.5796e-02,  1.1137e-02, -1.5699e-02, -4.3949e-02,\n",
      "         -3.1017e-02,  5.0448e-02, -3.7748e-02, -9.3576e-03, -4.2779e-03,\n",
      "          4.6764e-04, -1.4065e-02, -4.3150e-03, -2.6817e-02,  4.4964e-02,\n",
      "          2.5290e-02,  2.2766e-02,  1.2111e-02, -2.0272e-02, -2.5734e-02,\n",
      "          1.2487e-02, -5.1973e-03, -7.0608e-01, -2.1287e-03,  2.0742e-02,\n",
      "         -3.7818e-02, -2.5581e-02, -5.1604e-02, -3.2381e-02, -3.5656e-02,\n",
      "         -1.6238e-02,  7.9131e-03,  1.7351e-02,  3.3567e-03,  1.0270e-02,\n",
      "          1.7973e-02, -1.4270e-01,  3.6981e-03, -3.5925e-02,  3.1900e-02,\n",
      "         -3.2463e-02, -2.7144e-02, -2.0587e-02, -3.2064e-02, -3.7898e-02,\n",
      "         -1.9619e-02, -2.3221e-02, -3.2515e-02,  1.9371e-02,  7.5140e-03,\n",
      "         -3.9691e-02,  5.0754e-02, -1.6339e-02,  9.2582e-03,  2.1091e-02,\n",
      "          3.2845e-03,  5.8339e-03, -1.5163e-02,  3.8725e-03, -3.3753e-02,\n",
      "         -2.3993e-02, -3.3787e-02, -3.1451e-03,  8.6662e-02, -1.2057e-02,\n",
      "         -1.9817e-02,  1.9393e-02, -4.7365e-02, -2.0944e-02,  1.9844e-02,\n",
      "          3.8499e-02, -2.6502e-02,  2.1460e-02,  5.8994e-04, -2.2858e-02,\n",
      "          2.1125e-02, -8.5193e-03,  4.9985e-02,  4.7599e-02,  8.4773e-04,\n",
      "         -3.7811e-02, -2.0009e-02, -1.8792e-03, -2.3176e-02, -4.5254e-03,\n",
      "         -1.1238e-02, -1.3399e-03,  2.1306e-02, -1.7920e-02, -9.3386e-03,\n",
      "         -9.6614e-04, -1.3660e-02,  2.4270e-02, -2.5276e-02,  1.2926e-02,\n",
      "         -3.1416e-03,  4.7621e-02, -7.4782e-03, -1.6420e-02, -7.5976e-03,\n",
      "         -2.2902e-03, -2.7909e-06, -5.4573e-03,  2.3010e-02,  2.6855e-02,\n",
      "         -2.6141e-02,  2.5824e-02, -7.7655e-03,  2.7275e-02, -3.8422e-03,\n",
      "          3.1582e-02, -4.9017e-03, -1.6256e-02,  9.3598e-03, -3.8353e-03,\n",
      "         -1.3678e-02,  3.3044e-02, -5.3327e-03, -4.3702e-02, -9.0234e-03,\n",
      "         -1.6234e-02,  2.2235e-02, -1.9467e-02, -5.8858e-04, -1.2051e-02,\n",
      "         -2.0804e-02,  4.4562e-03, -1.5142e-02, -5.5861e-02, -2.2417e-02,\n",
      "          2.9875e-02,  1.4904e-02, -9.1017e-03, -3.6185e-03,  1.9238e-02,\n",
      "          2.3443e-02, -7.2083e-03, -2.0018e-02,  2.4718e-02,  1.9821e-03,\n",
      "         -3.3936e-02,  2.0612e-02, -1.4360e-03,  1.5961e-02,  6.9374e-03,\n",
      "          2.4512e-03, -8.3201e-03, -1.5897e-02,  1.4665e-01, -4.0152e-02,\n",
      "          4.8634e-02, -1.6597e-02,  4.0812e-03,  5.1482e-02, -1.4934e-02,\n",
      "          3.4008e-02,  4.8138e-02,  4.9635e-02, -1.4270e-02, -6.4101e-03,\n",
      "          8.2449e-04, -9.3810e-03, -8.2564e-03,  9.9694e-03,  1.2804e-02,\n",
      "         -3.3831e-02,  2.3309e-03, -3.8402e-02, -7.5109e-03, -4.1520e-02,\n",
      "         -1.1479e-02,  5.9454e-03,  1.3644e-02,  2.5490e-02, -4.8367e-03,\n",
      "          3.1695e-02,  2.3238e-02, -7.9066e-03, -6.0536e-03,  3.8055e-02,\n",
      "          7.3479e-03,  2.0241e-02, -1.0360e-03, -2.3568e-02, -2.0619e-02,\n",
      "          6.3505e-03, -3.0478e-03, -2.6562e-02, -1.7758e-01, -6.1842e-02,\n",
      "         -1.6653e-02,  6.3742e-03, -1.0811e-02,  7.3439e-02, -9.6847e-03,\n",
      "          7.6565e-03, -1.9023e-02, -3.0579e-02,  3.4826e-03, -2.0010e-02,\n",
      "          3.0947e-02, -1.1018e-02,  1.2114e-02, -3.1000e-03, -2.1969e-02,\n",
      "          2.2076e-02,  2.2143e-02,  2.3069e-02, -1.4666e-02,  9.4991e-03,\n",
      "         -9.9475e-03,  8.1416e-03, -4.2984e-03, -2.2468e-02, -8.5023e-04,\n",
      "          1.4623e-02,  3.7518e-05, -4.3580e-03,  2.4715e-02, -1.3990e-02,\n",
      "         -2.4762e-02,  4.1186e-02,  4.9796e-03,  2.2414e-02, -7.4968e-03,\n",
      "          2.6509e-02,  3.7598e-03, -2.3172e-02, -3.1973e-02, -2.1965e-02,\n",
      "          2.7571e-02, -1.4208e-02,  8.0662e-04, -5.5419e-03, -1.4398e-02,\n",
      "         -3.1130e-02,  2.7709e-03,  1.8964e-02, -2.6688e-02, -4.9833e-02,\n",
      "         -4.2639e-04,  4.8657e-02,  8.6615e-02,  3.9439e-02,  4.1710e-02,\n",
      "          1.1246e-02,  2.0856e-04,  4.0898e-02, -2.8924e-03,  3.6810e-02,\n",
      "         -5.0712e-03,  1.8917e-01, -1.6763e-02,  3.9974e-02,  4.0743e-02,\n",
      "          2.5207e-02, -1.3376e-02,  2.5871e-02, -8.6091e-03,  2.1531e-02,\n",
      "          2.1565e-02, -7.5535e-03, -5.4052e-03, -1.0624e-02,  5.6130e-03,\n",
      "         -9.5446e-03,  3.0417e-03,  1.7188e-02,  1.9101e-02,  3.8678e-02,\n",
      "         -2.5197e-03,  2.5219e-02,  1.7866e-02,  5.0714e-03, -2.3098e-02,\n",
      "          2.4517e-03,  1.1557e-02, -2.5159e-02,  4.2797e-02,  9.1634e-03,\n",
      "         -2.2412e-02, -3.9784e-02,  1.7808e-02, -2.6482e-02,  3.5525e-02,\n",
      "          3.3218e-02, -1.7822e-02,  7.1023e-02,  9.0001e-03, -6.3363e-03,\n",
      "          3.7161e-02,  1.4001e-02,  2.1329e-02,  8.8468e-02, -5.8307e-02,\n",
      "         -1.5214e-02,  1.5528e-02, -2.0853e-03,  1.0024e-02,  8.7057e-03,\n",
      "         -2.0645e-02,  3.5476e-02,  2.1056e-02, -2.1851e-02,  1.0576e-02,\n",
      "         -2.7751e-02, -3.0503e-02,  1.3705e-02, -8.9655e-02, -2.3749e-02,\n",
      "         -4.4554e-02, -4.0617e-02, -4.9807e-02, -6.4315e-03,  2.2410e-02,\n",
      "         -1.5010e-02,  1.6636e-02,  5.0398e-03, -9.5938e-03, -1.4450e-03,\n",
      "         -1.9286e-02, -3.8478e-02,  1.6421e-02, -4.6689e-03, -1.6075e-02,\n",
      "          3.1790e-02, -1.5969e-02, -1.4286e-02, -4.0221e-02, -2.7559e-02,\n",
      "         -2.4964e-02, -2.2209e-02,  6.0020e-03, -3.0016e-02, -2.8210e-02,\n",
      "         -1.5806e-03, -4.2783e-02,  7.3144e-03,  1.3334e-01, -3.8399e-02,\n",
      "          4.3863e-03, -2.8361e-02, -3.3183e-02,  1.4006e-02, -2.9007e-02,\n",
      "         -1.4951e-02, -2.9338e-02,  2.1794e-02, -3.1726e-02, -3.6384e-02,\n",
      "         -9.8522e-03, -4.8781e-02,  1.3385e-02, -6.8179e-02, -1.2512e-02,\n",
      "          7.7196e-03,  1.3691e-02, -1.0683e-02, -4.8578e-02, -2.7278e-02,\n",
      "         -2.0583e-03,  3.2561e-02, -1.2675e-02,  3.1892e-03, -5.2575e-04,\n",
      "         -2.8163e-02,  2.8904e-02,  7.1305e-03,  3.8146e-02, -1.9221e-02,\n",
      "         -4.2977e-02,  1.2214e-02,  8.5276e-03,  2.8302e-02, -1.3033e-02,\n",
      "          2.5608e-02, -1.3608e-02,  1.6718e-02,  2.8990e-03, -4.3698e-02,\n",
      "         -7.4032e-02, -2.6416e-02,  1.0945e-02,  1.1447e-02, -3.7815e-02,\n",
      "         -1.1942e-02, -5.0286e-03, -4.4610e-02,  1.1281e-02, -8.2571e-03,\n",
      "          2.0305e-02, -1.7635e-03, -4.0612e-02,  2.6316e-02,  3.2740e-02,\n",
      "         -2.2520e-02,  6.3391e-02,  1.4634e-03, -1.2913e-02,  1.9313e-02,\n",
      "          4.7665e-02, -9.1261e-03,  1.0974e-02, -4.1957e-04,  8.3786e-03,\n",
      "         -2.6111e-02, -3.1666e-02, -6.9072e-03,  1.7778e-02, -1.3302e-02,\n",
      "          3.4533e-02,  4.2176e-03, -3.1463e-02,  1.9343e-02,  1.9400e-02,\n",
      "          4.0177e-02,  2.1257e-02, -1.9456e-02, -1.9116e-02,  4.9285e-04,\n",
      "          2.4418e-02, -3.4124e-02,  1.5482e-03,  2.9613e-02,  8.1771e-03,\n",
      "          1.4174e-02,  1.6727e-02, -3.5459e-02, -2.2856e-02, -3.7267e-02,\n",
      "         -1.9149e-03, -2.0115e-02,  2.1788e-02, -1.2265e-02, -1.4306e-02,\n",
      "          8.2402e-03,  5.7664e-04,  7.8963e-03, -1.9733e-02,  6.7024e-02,\n",
      "         -4.4181e-02, -1.6961e-02]])\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T12:47:19.453836Z",
     "start_time": "2024-09-14T12:47:19.442251Z"
    }
   },
   "cell_type": "code",
   "source": "text_embeddings.shape",
   "id": "63140b0a8ae4ac9f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T12:47:30.053115Z",
     "start_time": "2024-09-14T12:47:30.045068Z"
    }
   },
   "cell_type": "code",
   "source": "image_embeddings.shape",
   "id": "a3dfe043e0e64b30",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6eb8ff98bcd5fc2f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

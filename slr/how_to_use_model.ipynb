{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-30T03:23:56.812408Z",
     "start_time": "2024-09-30T03:23:54.991530Z"
    }
   },
   "source": [
    "from transformers.testing_utils import torch_device\n",
    "\n",
    "from slr.models.CorrNet import CorrNet\n",
    "from slr.datasets.Phoenix2014DataModule import Phoenix2014DataModule\n",
    "import numpy as np\n",
    "import os\n",
    "from slr.models.utils.decode import Decode"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T03:23:58.328162Z",
     "start_time": "2024-09-30T03:23:57.109887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load model\n",
    "model = CorrNet.load_from_checkpoint(\n",
    "    \"/new_home/xzj23/workspace/SLR/experiments/Phoenix2014/CorrNet/2024-09-23_12-48-46/checkpoints/epoch=21-DEV_WER=19.10.ckpt\")\n",
    "model"
   ],
   "id": "9d44c0b5a25831bb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CorrNet(\n",
       "  (conv2d): ResNet(\n",
       "    (conv1): Conv3d(3, 64, kernel_size=(1, 7, 7), stride=(1, 2, 2), padding=(0, 3, 3), bias=False)\n",
       "    (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (corr1): Get_Correlation(\n",
       "      (down_conv): Conv3d(128, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (down_conv2): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (spatial_aggregation1): Conv3d(8, 8, kernel_size=(9, 3, 3), stride=(1, 1, 1), padding=(4, 1, 1), groups=8)\n",
       "      (spatial_aggregation2): Conv3d(8, 8, kernel_size=(9, 3, 3), stride=(1, 1, 1), padding=(4, 2, 2), dilation=(1, 2, 2), groups=8)\n",
       "      (spatial_aggregation3): Conv3d(8, 8, kernel_size=(9, 3, 3), stride=(1, 1, 1), padding=(4, 3, 3), dilation=(1, 3, 3), groups=8)\n",
       "      (conv_back): Conv3d(8, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv3d(128, 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (corr2): Get_Correlation(\n",
       "      (down_conv): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (down_conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (spatial_aggregation1): Conv3d(16, 16, kernel_size=(9, 3, 3), stride=(1, 1, 1), padding=(4, 1, 1), groups=16)\n",
       "      (spatial_aggregation2): Conv3d(16, 16, kernel_size=(9, 3, 3), stride=(1, 1, 1), padding=(4, 2, 2), dilation=(1, 2, 2), groups=16)\n",
       "      (spatial_aggregation3): Conv3d(16, 16, kernel_size=(9, 3, 3), stride=(1, 1, 1), padding=(4, 3, 3), dilation=(1, 3, 3), groups=16)\n",
       "      (conv_back): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv3d(256, 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (corr3): Get_Correlation(\n",
       "      (down_conv): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (down_conv2): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (spatial_aggregation1): Conv3d(32, 32, kernel_size=(9, 3, 3), stride=(1, 1, 1), padding=(4, 1, 1), groups=32)\n",
       "      (spatial_aggregation2): Conv3d(32, 32, kernel_size=(9, 3, 3), stride=(1, 1, 1), padding=(4, 2, 2), dilation=(1, 2, 2), groups=32)\n",
       "      (spatial_aggregation3): Conv3d(32, 32, kernel_size=(9, 3, 3), stride=(1, 1, 1), padding=(4, 3, 3), dilation=(1, 3, 3), groups=32)\n",
       "      (conv_back): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (conv1d): TemporalConv(\n",
       "    (temporal_conv): Sequential(\n",
       "      (0): Conv1d(512, 1024, kernel_size=(5,), stride=(1,))\n",
       "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "      (4): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,))\n",
       "      (5): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    )\n",
       "    (fc): NormLinear()\n",
       "  )\n",
       "  (temporal_model): BiLSTMLayer(\n",
       "    (rnn): LSTM(1024, 512, num_layers=2, dropout=0.3, bidirectional=True)\n",
       "  )\n",
       "  (classifier): NormLinear()\n",
       "  (ctc_loss): CTCLoss()\n",
       "  (dist_loss): SeqKD(\n",
       "    (kdloss): KLDivLoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T03:24:05.922198Z",
     "start_time": "2024-09-30T03:23:58.459236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get data\n",
    "\n",
    "with open(os.path.join(\"/new_home/xzj23/workspace/SLR/data/global_files/gloss_dict/phoenix2014_gloss_dict.npy\"),\n",
    "          'rb') as f:\n",
    "    gloss_dict = np.load(f, allow_pickle=True).item()\n",
    "datamodule = Phoenix2014DataModule(\n",
    "    features_path=\"/new_home/xzj23/workspace/SLR/data/phoenix2014/phoenix-2014-multisigner/features/fullFrame-256x256px\",\n",
    "    annotations_path=\"/new_home/xzj23/workspace/SLR/data/phoenix2014/phoenix-2014-multisigner/annotations/manual\",\n",
    "    gloss_dict=gloss_dict,\n",
    "    batch_size=2, num_workers=10\n",
    ")\n",
    "datamodule.setup(stage=\"fit\")\n",
    "\n",
    "batch = datamodule.train_dataloader().__iter__().__next__()\n",
    "x, x_lgt, y, y_lgt, info = batch"
   ],
   "id": "bc52d0b38b7548a8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T03:24:05.998002Z",
     "start_time": "2024-09-30T03:24:05.989193Z"
    }
   },
   "cell_type": "code",
   "source": "x.shape",
   "id": "83541703a549029e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 232, 3, 224, 224])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T03:24:06.062607Z",
     "start_time": "2024-09-30T03:24:06.057122Z"
    }
   },
   "cell_type": "code",
   "source": "y",
   "id": "c50cede701a099c0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 951, 1120, 1134, 1120,  810,  142,  526,  396,    8,  569,  569,  569,\n",
       "         569,  569, 1149, 1063,  719, 1149,  723,  565,  253,  465,  465,   20,\n",
       "         132, 1195, 1113,  906])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T03:24:06.127066Z",
     "start_time": "2024-09-30T03:24:06.117837Z"
    }
   },
   "cell_type": "code",
   "source": "x_lgt",
   "id": "3fa80fba1f9bcc2a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([232, 108])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T03:24:06.191643Z",
     "start_time": "2024-09-30T03:24:06.182675Z"
    }
   },
   "cell_type": "code",
   "source": "y_lgt",
   "id": "c7f80ea7e764fbad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 10])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T03:24:06.257726Z",
     "start_time": "2024-09-30T03:24:06.247489Z"
    }
   },
   "cell_type": "code",
   "source": "info",
   "id": "fc757c18874565d7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[folder            31January_2011_Monday_heute_default-1/1/*.png\n",
       " signer                                                 Signer07\n",
       " annotation    SUED WETTER WINTER WETTER RUHIG BLEIBEN LANG H...\n",
       " Name: 31January_2011_Monday_heute_default-1, dtype: object,\n",
       " folder        04October_2012_Thursday_tagesschau_default-12/...\n",
       " signer                                                 Signer05\n",
       " annotation    NORDRAUM MAXIMAL ELF IX IX ACHTZEHN BIS ZWEIZW...\n",
       " Name: 04October_2012_Thursday_tagesschau_default-12, dtype: object]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T03:24:06.772503Z",
     "start_time": "2024-09-30T03:24:06.311847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# to device\n",
    "device = \"cuda:1\"\n",
    "model = model.to(device)\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "x_lgt = x_lgt.to(device)\n",
    "y_lgt = y_lgt.to(device)\n",
    "\n",
    "# forward\n",
    "model.eval()\n",
    "conv_logits, y_hat_logits, y_hat_lgt = model(x, x_lgt)"
   ],
   "id": "eaeaea6075ab9d92",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T03:24:06.792028Z",
     "start_time": "2024-09-30T03:24:06.790218Z"
    }
   },
   "cell_type": "code",
   "source": "conv_logits.shape",
   "id": "38c539e7ce061072",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([55, 2, 1296])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T03:24:06.866561Z",
     "start_time": "2024-09-30T03:24:06.855968Z"
    }
   },
   "cell_type": "code",
   "source": "y_hat_logits.shape",
   "id": "cb0e897fbe8fb93",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([55, 2, 1296])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T03:24:06.968426Z",
     "start_time": "2024-09-30T03:24:06.959936Z"
    }
   },
   "cell_type": "code",
   "source": "y_hat_lgt.shape",
   "id": "202498c72eddb49e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T03:24:07.043456Z",
     "start_time": "2024-09-30T03:24:07.036078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# set decoder\n",
    "decoder = Decode(gloss_dict=gloss_dict, num_classes=1296, search_mode='beam_search')"
   ],
   "id": "cb236bb0a4e3494e",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T03:24:07.128910Z",
     "start_time": "2024-09-30T03:24:07.099467Z"
    }
   },
   "cell_type": "code",
   "source": "sentence = decoder.decode(y_hat_logits.softmax(dim=-1).cpu(), y_hat_lgt.cpu(), batch_first=False, probs=True)",
   "id": "9d61f0953278a10e",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T03:24:07.189199Z",
     "start_time": "2024-09-30T03:24:07.181408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for s in sentence:\n",
    "    print(\" \".join([t[0] for t in s]))"
   ],
   "id": "f33b852aa9b0cc5f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUED WETTER WINTER WETTER RUHIG BLEIBEN LANG ABER MEHR VON NORD WOLKE\n",
      "NORDRAUM MAXIMAL ELF SUED IX ACHTZEHN BIS ZWEIZWANZIG WENN SONNE\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T03:24:07.651780Z",
     "start_time": "2024-09-30T03:24:07.336635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "501c0e743772de26",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T03:24:08.191931Z",
     "start_time": "2024-09-30T03:24:07.772099Z"
    }
   },
   "cell_type": "code",
   "source": "dddd = model.predict_step((x, x_lgt, y, y_lgt,info),0)",
   "id": "77719271d41df4aa",
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 356.00 MiB (GPU 1; 23.69 GiB total capacity; 22.83 GiB already allocated; 73.94 MiB free; 23.23 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m dddd \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_lgt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_lgt\u001B[49m\u001B[43m,\u001B[49m\u001B[43minfo\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/SLR/slr/models/SLRBaseModel.py:277\u001B[0m, in \u001B[0;36mSLRBaseModel.predict_step\u001B[0;34m(self, batch, batch_idx, dataloader_idx)\u001B[0m\n\u001B[1;32m    265\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict_step\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch: Any, batch_idx: \u001B[38;5;28mint\u001B[39m, dataloader_idx: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    266\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    267\u001B[0m \u001B[38;5;124;03m    执行单个预测步骤，即处理一个批次的数据用于预测。\u001B[39;00m\n\u001B[1;32m    268\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    275\u001B[0m \u001B[38;5;124;03m    - decoded: 解码后的预测结果。\u001B[39;00m\n\u001B[1;32m    276\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 277\u001B[0m     _, decoded, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    279\u001B[0m     \u001B[38;5;66;03m# 可以在此处添加额外的逻辑来处理预测结果，例如保存到文件、返回特定格式的数据等。\u001B[39;00m\n\u001B[1;32m    280\u001B[0m     \u001B[38;5;66;03m# 示例: 将预测结果转换为易于理解的形式或直接返回预测结果。\u001B[39;00m\n\u001B[1;32m    282\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m decoded\n",
      "File \u001B[0;32m~/workspace/SLR/slr/models/CorrNet.py:85\u001B[0m, in \u001B[0;36mCorrNet.step_forward\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m     83\u001B[0m x, x_lgt, y, y_lgt, info \u001B[38;5;241m=\u001B[39m batch\n\u001B[1;32m     84\u001B[0m \u001B[38;5;66;03m# 模型正向传播\u001B[39;00m\n\u001B[0;32m---> 85\u001B[0m conv1d_hat, y_hat, y_hat_lgt \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_lgt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     87\u001B[0m conv1d_hat_softmax \u001B[38;5;241m=\u001B[39m conv1d_hat\u001B[38;5;241m.\u001B[39mlog_softmax(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     88\u001B[0m y_hat_softmax \u001B[38;5;241m=\u001B[39m y_hat\u001B[38;5;241m.\u001B[39mlog_softmax(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/.conda/envs/slr/lib/python3.10/site-packages/torch/nn/modules/module.py:1212\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1209\u001B[0m     bw_hook \u001B[38;5;241m=\u001B[39m hooks\u001B[38;5;241m.\u001B[39mBackwardHook(\u001B[38;5;28mself\u001B[39m, full_backward_hooks)\n\u001B[1;32m   1210\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m bw_hook\u001B[38;5;241m.\u001B[39msetup_input_hook(\u001B[38;5;28minput\u001B[39m)\n\u001B[0;32m-> 1212\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1213\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks:\n\u001B[1;32m   1214\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m*\u001B[39m_global_forward_hooks\u001B[38;5;241m.\u001B[39mvalues(), \u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks\u001B[38;5;241m.\u001B[39mvalues()):\n",
      "File \u001B[0;32m~/workspace/SLR/slr/models/CorrNet.py:55\u001B[0m, in \u001B[0;36mCorrNet.forward\u001B[0;34m(self, x, x_lgt)\u001B[0m\n\u001B[1;32m     53\u001B[0m batch_size, sequence_length, channels, height, width \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mshape\n\u001B[1;32m     54\u001B[0m reshaped_inputs \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m4\u001B[39m)\n\u001B[0;32m---> 55\u001B[0m convolved \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreshaped_inputs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mview(batch_size, sequence_length, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     57\u001B[0m \u001B[38;5;66;03m# 通过一维卷积层\u001B[39;00m\n\u001B[1;32m     58\u001B[0m conv1d_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv1d(convolved, x_lgt)\n",
      "File \u001B[0;32m~/.conda/envs/slr/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/workspace/SLR/slr/models/modules/resnet.py:265\u001B[0m, in \u001B[0;36mResNet.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    262\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmaxpool(x)\n\u001B[1;32m    264\u001B[0m \u001B[38;5;66;03m# 通过模型的第一层\u001B[39;00m\n\u001B[0;32m--> 265\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayer1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    266\u001B[0m \u001B[38;5;66;03m# 通过模型的第二层\u001B[39;00m\n\u001B[1;32m    267\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer2(x)\n",
      "File \u001B[0;32m~/.conda/envs/slr/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.conda/envs/slr/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    202\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    203\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 204\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    205\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/.conda/envs/slr/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/workspace/SLR/slr/models/modules/resnet.py:148\u001B[0m, in \u001B[0;36mBasicBlock.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    145\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu(out)\n\u001B[1;32m    147\u001B[0m \u001B[38;5;66;03m# 主路径第二部分：卷积、批量归一化\u001B[39;00m\n\u001B[0;32m--> 148\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    149\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn2(out)\n\u001B[1;32m    151\u001B[0m \u001B[38;5;66;03m# 如果需要下采样，则对残差进行下采样\u001B[39;00m\n",
      "File \u001B[0;32m~/.conda/envs/slr/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.conda/envs/slr/lib/python3.10/site-packages/torch/nn/modules/conv.py:613\u001B[0m, in \u001B[0;36mConv3d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    612\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 613\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/slr/lib/python3.10/site-packages/torch/nn/modules/conv.py:608\u001B[0m, in \u001B[0;36mConv3d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    596\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    597\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv3d(\n\u001B[1;32m    598\u001B[0m         F\u001B[38;5;241m.\u001B[39mpad(\n\u001B[1;32m    599\u001B[0m             \u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    606\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups,\n\u001B[1;32m    607\u001B[0m     )\n\u001B[0;32m--> 608\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv3d\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    609\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\n\u001B[1;32m    610\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 356.00 MiB (GPU 1; 23.69 GiB total capacity; 22.83 GiB already allocated; 73.94 MiB free; 23.23 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T03:25:09.036454Z",
     "start_time": "2024-09-30T03:24:47.133647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = model.to(\"cpu\")\n",
    "ddd = model.predict_step(batch,0)"
   ],
   "id": "da7154ad441172f2",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T03:25:12.824472Z",
     "start_time": "2024-09-30T03:25:12.817473Z"
    }
   },
   "cell_type": "code",
   "source": "ddd",
   "id": "c348147e4c681e43",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('SUED', 0),\n",
       "  ('WETTER', 1),\n",
       "  ('WINTER', 2),\n",
       "  ('WETTER', 3),\n",
       "  ('RUHIG', 4),\n",
       "  ('BLEIBEN', 5),\n",
       "  ('LANG', 6),\n",
       "  ('ABER', 7),\n",
       "  ('MEHR', 8),\n",
       "  ('VON', 9),\n",
       "  ('NORD', 10),\n",
       "  ('WOLKE', 11)],\n",
       " [('NORDRAUM', 0),\n",
       "  ('MAXIMAL', 1),\n",
       "  ('ELF', 2),\n",
       "  ('SUED', 3),\n",
       "  ('IX', 4),\n",
       "  ('ACHTZEHN', 5),\n",
       "  ('BIS', 6),\n",
       "  ('ZWEIZWANZIG', 7),\n",
       "  ('WENN', 8),\n",
       "  ('SONNE', 9)]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9f06f54aa09c36dc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

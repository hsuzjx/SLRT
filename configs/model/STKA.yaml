# configs/model/STKA.yaml

name: "STKA"

# for after backward
test_param: false

network:
  st_attention_module_prams: [
    [ 64, 64, 16, 7, 2 ],
    [ 64, 64, 16, 3, 1 ],
    [ 64, 128, 32, 3, 1 ],
    [ 128, 128, 32, 3, 1 ],
    [ 128, 256, 64, 3, 2 ],
    [ 256, 256, 64, 3, 1 ],
    [ 256, 256, 64, 3, 1 ],
    [ 256, 256, 64, 3, 1 ],
  ]
  head_cfg: {
    'input_size': 256,
    'hidden_size': 512,
    'ff_size': 2048,
    'pe': True,
    'ff_kernelsize': [ 3, 3 ]
  }

# for optimizer and lr_scheduler
optimizer:
  lr: 0.001
  weight_decay: 0.001
  betas:
    - 0.9
    - 0.998

lr_scheduler:
  T_max: 100

# for early stop
patience_early_stop: 50

# for callbacks checkpoint
save_last: true
save_top_k: 3